{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 3 \n",
    "# CS584 MACHINE LEARNING \n",
    "# JULEN FERRO BAÃ‘ALES\n",
    "This Jupyter Notebook will include the coding of the Homework 3 related to the subject CS584 Machine Learning, as well as some comments made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, some basic auxiliary functions will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning(df):\n",
    "    df = df.drop(['rightdown'], axis=1, level= 1)\n",
    "    df = df.drop(['topleft'], axis=1, level= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that must be done, is to read the CSV file with the location data that has been obtained after processing the mice images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th colspan=\"36\" halign=\"left\">annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>Unnamed: 1_level_1</th>\n",
       "      <th>Unnamed: 2_level_1</th>\n",
       "      <th colspan=\"18\" halign=\"left\">mouse1</th>\n",
       "      <th colspan=\"18\" halign=\"left\">mouse2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th>Unnamed: 1_level_2</th>\n",
       "      <th>Unnamed: 2_level_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">topleft</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightdown</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "      <th colspan=\"2\" halign=\"left\">topleft</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightdown</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>Unnamed: 1_level_3</th>\n",
       "      <th>Unnamed: 2_level_3</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>12.903231</td>\n",
       "      <td>544.739689</td>\n",
       "      <td>331.769622</td>\n",
       "      <td>517.657886</td>\n",
       "      <td>21.639296</td>\n",
       "      <td>504.553788</td>\n",
       "      <td>51.341919</td>\n",
       "      <td>464.367887</td>\n",
       "      <td>59.204378</td>\n",
       "      <td>532.509198</td>\n",
       "      <td>169.278803</td>\n",
       "      <td>481.840018</td>\n",
       "      <td>168.405197</td>\n",
       "      <td>462.620673</td>\n",
       "      <td>251.397819</td>\n",
       "      <td>307.118707</td>\n",
       "      <td>295.951753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>286.152150</td>\n",
       "      <td>140.449787</td>\n",
       "      <td>516.784280</td>\n",
       "      <td>315.171098</td>\n",
       "      <td>515.910673</td>\n",
       "      <td>175.394049</td>\n",
       "      <td>488.828870</td>\n",
       "      <td>148.312246</td>\n",
       "      <td>457.379034</td>\n",
       "      <td>152.680279</td>\n",
       "      <td>478.345591</td>\n",
       "      <td>234.799295</td>\n",
       "      <td>425.055592</td>\n",
       "      <td>229.557655</td>\n",
       "      <td>412.825100</td>\n",
       "      <td>262.754704</td>\n",
       "      <td>293.141002</td>\n",
       "      <td>285.468475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>238.977396</td>\n",
       "      <td>154.427492</td>\n",
       "      <td>394.479362</td>\n",
       "      <td>225.189623</td>\n",
       "      <td>247.713462</td>\n",
       "      <td>212.085524</td>\n",
       "      <td>267.806412</td>\n",
       "      <td>203.349459</td>\n",
       "      <td>272.174445</td>\n",
       "      <td>198.107820</td>\n",
       "      <td>300.129855</td>\n",
       "      <td>198.107820</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>187.624541</td>\n",
       "      <td>336.821330</td>\n",
       "      <td>189.371754</td>\n",
       "      <td>404.089034</td>\n",
       "      <td>217.327164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>230.241331</td>\n",
       "      <td>166.657984</td>\n",
       "      <td>310.613133</td>\n",
       "      <td>239.167328</td>\n",
       "      <td>287.899363</td>\n",
       "      <td>192.866180</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>184.130115</td>\n",
       "      <td>280.036904</td>\n",
       "      <td>196.360606</td>\n",
       "      <td>253.828707</td>\n",
       "      <td>196.360606</td>\n",
       "      <td>269.553625</td>\n",
       "      <td>210.338311</td>\n",
       "      <td>245.092642</td>\n",
       "      <td>221.695196</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>234.799295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>233.735757</td>\n",
       "      <td>173.646836</td>\n",
       "      <td>299.256248</td>\n",
       "      <td>261.007491</td>\n",
       "      <td>240.724609</td>\n",
       "      <td>187.624541</td>\n",
       "      <td>251.207888</td>\n",
       "      <td>191.118967</td>\n",
       "      <td>258.196740</td>\n",
       "      <td>185.003721</td>\n",
       "      <td>257.323134</td>\n",
       "      <td>208.591098</td>\n",
       "      <td>287.899363</td>\n",
       "      <td>194.613393</td>\n",
       "      <td>281.784117</td>\n",
       "      <td>224.316016</td>\n",
       "      <td>252.955101</td>\n",
       "      <td>259.260278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scorer Unnamed: 1_level_0  \\\n",
       "    individuals Unnamed: 1_level_1   \n",
       "      bodyparts Unnamed: 1_level_2   \n",
       "         coords Unnamed: 1_level_3   \n",
       "0  labeled-data               24.0   \n",
       "1  labeled-data               24.0   \n",
       "2  labeled-data               24.0   \n",
       "3  labeled-data               24.0   \n",
       "4  labeled-data               24.0   \n",
       "\n",
       "                                  Unnamed: 2_level_0  annotation              \\\n",
       "                                  Unnamed: 2_level_1      mouse1               \n",
       "                                  Unnamed: 2_level_2     topleft               \n",
       "                                  Unnamed: 2_level_3           x           y   \n",
       "0  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  273.048052   12.903231   \n",
       "1  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  286.152150  140.449787   \n",
       "2  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  238.977396  154.427492   \n",
       "3  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  230.241331  166.657984   \n",
       "4  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  233.735757  173.646836   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "    rightdown                    nose                 leftear               \n",
       "            x           y           x           y           x           y   \n",
       "0  544.739689  331.769622  517.657886   21.639296  504.553788   51.341919   \n",
       "1  516.784280  315.171098  515.910673  175.394049  488.828870  148.312246   \n",
       "2  394.479362  225.189623  247.713462  212.085524  267.806412  203.349459   \n",
       "3  310.613133  239.167328  287.899363  192.866180  273.048052  184.130115   \n",
       "4  299.256248  261.007491  240.724609  187.624541  251.207888  191.118967   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "     rightear                 leftHip                rightHip               \n",
       "            x           y           x           y           x           y   \n",
       "0  464.367887   59.204378  532.509198  169.278803  481.840018  168.405197   \n",
       "1  457.379034  152.680279  478.345591  234.799295  425.055592  229.557655   \n",
       "2  272.174445  198.107820  300.129855  198.107820  303.624281  187.624541   \n",
       "3  280.036904  196.360606  253.828707  196.360606  269.553625  210.338311   \n",
       "4  258.196740  185.003721  257.323134  208.591098  287.899363  194.613393   \n",
       "\n",
       "                                                                             \\\n",
       "                                                   mouse2                     \n",
       "     tailBase                 tailEnd             topleft     rightdown       \n",
       "            x           y           x           y       x   y         x   y   \n",
       "0  462.620673  251.397819  307.118707  295.951753     NaN NaN       NaN NaN   \n",
       "1  412.825100  262.754704  293.141002  285.468475     NaN NaN       NaN NaN   \n",
       "2  336.821330  189.371754  404.089034  217.327164     NaN NaN       NaN NaN   \n",
       "3  245.092642  221.695196  303.624281  234.799295     NaN NaN       NaN NaN   \n",
       "4  281.784117  224.316016  252.955101  259.260278     NaN NaN       NaN NaN   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "  nose     leftear     rightear     leftHip     rightHip     tailBase       \n",
       "     x   y       x   y        x   y       x   y        x   y        x   y   \n",
       "0  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "1  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "2  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "3  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "4  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "\n",
       "               \n",
       "               \n",
       "  tailEnd      \n",
       "        x   y  \n",
       "0     NaN NaN  \n",
       "1     NaN NaN  \n",
       "2     NaN NaN  \n",
       "3     NaN NaN  \n",
       "4     NaN NaN  "
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# reading the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\", header = [0, 1, 2, 3])\n",
    "df = pd.DataFrame(df) \n",
    "\n",
    "size = os.path.getsize(r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\")\n",
    "\n",
    "# displaying the contents of the CSV file\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, the dataset will be processed in order to get the dataset structure needed to feed the Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "58 rows were eliminated due to issues related to NaN values\n",
      "\n",
      "\n",
      "     annotation                                                              \\\n",
      "           nose                 leftear                rightear               \n",
      "              x           y           x           y           x           y   \n",
      "26   227.620511  239.167328  250.334281  214.706344  221.505265  208.591098   \n",
      "27   380.501658  201.602246  364.776740  194.613393  369.144772  203.349459   \n",
      "28   285.278543  200.728639  273.921658  194.613393  295.761822  194.613393   \n",
      "31   320.222805  199.855033  302.750674  204.223065  322.843625  208.591098   \n",
      "32   342.062969  108.126345  317.601986   95.022246  324.590838   99.390279   \n",
      "35   118.419692   37.364214  155.111167   65.319624  158.605593   57.457165   \n",
      "36   123.661331   23.386509  162.973626   39.111427  161.226413   24.260116   \n",
      "37   466.988706  304.687819  424.181985  267.996344  431.170838  281.974049   \n",
      "38   116.672479  105.505525  135.891823  112.494377  148.122315  112.494377   \n",
      "39    93.958708   51.341919  117.546085   63.572411  127.155757   56.583558   \n",
      "40   155.111167  210.338311  143.754282  199.855033  170.836085  197.234213   \n",
      "41   358.661494  291.583721  343.810182  253.145032  321.970019  261.007491   \n",
      "42   466.988706  312.550278  418.940346  274.111590  417.193133  284.594868   \n",
      "43   554.349361  267.122737  506.301001  247.903393  525.520345  256.639459   \n",
      "44   106.189200  154.427492  135.891823  163.163557  144.627888  155.301099   \n",
      "45    56.393627   67.066837   93.958708   74.055689  100.073954   64.446017   \n",
      "46    97.453135   85.412574   99.200348  121.230443  120.166905  113.367984   \n",
      "47   200.538708  229.557655  193.549855  217.327164  211.021986  217.327164   \n",
      "48   405.836248  248.777000  422.434772  233.052082  437.286083  232.178475   \n",
      "49   316.728379  315.171098  311.486740  299.446180  296.635429  306.435032   \n",
      "50    90.464282   46.100280  100.073954   42.605853  107.936413   28.628148   \n",
      "51   165.594446  112.494377  148.122315   93.275033  168.215265   84.538968   \n",
      "52   460.873460  146.565033  438.159690  145.691426  443.401329  166.657984   \n",
      "53   524.646739  211.211918  511.542640  224.316016  482.713624  182.382902   \n",
      "54   265.185593  327.401589  271.300839  297.698966  245.092642  293.330934   \n",
      "55    97.453135  256.639459  128.902971  280.226835  135.018216  264.501918   \n",
      "56    76.486577  299.446180  114.925266  293.330934  114.925266  267.122737   \n",
      "59   327.211658  143.944213  296.635429  140.449787  297.509035  157.921918   \n",
      "64   263.438380  176.267656  280.910511  171.026016  261.691166  165.784377   \n",
      "65   222.378872  168.405197  237.230183  171.899623  244.219035  170.152410   \n",
      "72   293.141002  275.858803  287.025756  254.018639  256.449527  266.249131   \n",
      "74   314.107560  158.795525  259.943953  159.669131  259.943953  169.278803   \n",
      "75   197.044282  281.974049  228.494117  240.040934  183.940183  238.293721   \n",
      "76   128.902971  147.438640  148.995921  170.152410  156.858380  161.416344   \n",
      "77   180.445757  126.472082  172.583298  134.334541  191.802642  136.955361   \n",
      "78   322.843625  309.929458  309.739527  267.996344  281.784117  274.985196   \n",
      "81   135.891823  233.925688  114.925266  198.107820  163.847233  205.096672   \n",
      "83   146.375102   89.780607  157.731987  110.747164  170.836085  101.137492   \n",
      "84   150.743134  196.360606  176.951331  174.520443  150.743134  160.542738   \n",
      "85   299.256248  158.795525  275.668871  172.773230  295.761822  185.877328   \n",
      "86   202.285921   45.226673  191.802642   69.687656  212.769200   69.687656   \n",
      "87   328.958871  178.014869  303.624281  170.152410  299.256248  178.014869   \n",
      "89   236.356576  204.223065  233.735757  185.003721  252.955101  186.750934   \n",
      "92   289.646576  210.338311  270.427232  200.728639  273.921658  205.970279   \n",
      "93   274.795265  206.843885  258.196740  196.360606  266.932806  196.360606   \n",
      "94   308.865920  312.550278  286.152150  259.260278  264.311986  269.743557   \n",
      "95   464.367887  318.665524  431.170838  278.479622  416.319526  271.490770   \n",
      "96   265.185593  216.453557  301.877068  205.096672  293.141002  199.855033   \n",
      "97   248.587068  238.293721  280.910511  215.579951  258.196740  209.464705   \n",
      "98   349.925428  231.304869  361.282313  211.211918  342.062969  211.211918   \n",
      "105  204.033134  220.821590  216.263626  230.431262  237.230183  222.568803   \n",
      "106  198.791495  235.672901  174.330511  206.843885  177.824937  221.695196   \n",
      "107  125.408544  168.405197  114.925266  162.289951  144.627888  171.899623   \n",
      "108  119.293298   98.516673  147.248708  127.345689  121.914118  128.219295   \n",
      "109  142.880675   86.286181  146.375102   97.643066  161.226413   96.769460   \n",
      "110  145.501495   97.643066  149.869528  114.241591  165.594446  103.758312   \n",
      "112  272.174445  243.535360  224.126085  219.947983  246.839855  233.925688   \n",
      "114  275.668871  267.996344  266.932806  238.293721  258.196740  247.029786   \n",
      "115  452.137395  121.230443  463.494280  133.460935  480.092804  119.483230   \n",
      "117  259.943953  136.955361  218.010839  126.472082  224.999691  134.334541   \n",
      "118  158.605593  136.955361  180.445757  144.817820  183.066577  131.713722   \n",
      "119  363.029526  231.304869  359.535100  215.579951  342.936576  232.178475   \n",
      "120  242.471822  199.855033  265.185593  198.107820  258.196740  185.003721   \n",
      "121  493.196903  248.777000  469.609526  246.156180  480.092804  271.490770   \n",
      "122   71.244938  148.312246   95.705922  150.933066   93.958708  124.724869   \n",
      "123   73.865758   88.033394   62.508873   98.516673   86.096249   86.286181   \n",
      "124  171.709692  175.394049  198.791495  163.163557  190.055429  146.565033   \n",
      "125  425.055592  303.814212  459.999854  285.468475  435.538870  269.743557   \n",
      "26   342.936576  224.316016  349.925428  219.074377  370.018379  218.200770   \n",
      "27   418.066739  241.788147  425.929198  229.557655  410.204280  229.557655   \n",
      "28   361.282313   85.412574  348.178215  102.011099  372.639199  105.505525   \n",
      "31   444.274936  240.040934  423.308379  218.200770  418.940346  226.063229   \n",
      "32   314.107560  140.449787  333.326904  142.197000  348.178215  142.197000   \n",
      "35   318.475592  158.795525  327.211658  161.416344  338.568543  154.427492   \n",
      "36   207.527560  192.866180  236.356576  185.877328  250.334281  186.750934   \n",
      "37   255.575921  264.501918  275.668871  237.420114  273.921658  231.304869   \n",
      "38   205.780347  281.974049  226.746904  247.903393  196.170675  245.282573   \n",
      "39   134.144610  278.479622  152.490347  253.145032  159.479200  241.788147   \n",
      "40   217.137232  264.501918  214.516413  242.661754  197.044282  247.029786   \n",
      "41   462.620673  244.408967  466.988706  238.293721  492.323296  229.557655   \n",
      "42   224.999691  229.557655  191.802642  213.832737  264.311986  257.513065   \n",
      "43   514.163460  261.007491  518.531493  249.650606  497.564935  254.018639   \n",
      "44   212.769200  241.788147  244.219035  239.167328  247.713462  234.799295   \n",
      "45   538.624443  203.349459  529.014771  198.981426  508.048214  212.085524   \n",
      "46   272.174445  241.788147  300.129855  241.788147  315.854773  234.799295   \n",
      "47   636.468377   52.215525  612.881000   32.122575  593.661656   27.754542   \n",
      "48   573.568706  164.037164  582.304771  128.219295  566.579853  135.208148   \n",
      "49    74.739364  212.085524   83.475430  232.178475   95.705922  217.327164   \n",
      "50   219.758052   86.286181  243.345429  108.999951  245.092642   86.286181   \n",
      "51   190.929036  171.899623  202.285921  160.542738  193.549855  143.944213   \n",
      "52   516.784280  196.360606  522.899525  165.784377  504.553788  173.646836   \n",
      "53   490.576083  311.676671  478.345591  287.215688  539.498050  267.122737   \n",
      "54   422.434772  191.118967  443.401329  212.085524  459.126247  197.234213   \n",
      "55   184.813790  294.204540  191.802642  286.342081  179.572151  278.479622   \n",
      "56   381.375264  178.014869  342.936576  189.371754  361.282313  211.211918   \n",
      "59   368.271166  101.137492  355.167068  115.988804  375.260018  121.230443   \n",
      "64   476.598378  114.241591  486.208050  143.944213  450.390182  153.553885   \n",
      "65   270.427232  191.118967  249.460675  187.624541  274.795265  185.877328   \n",
      "72   301.003461  242.661754  331.579691  237.420114  351.672641  233.052082   \n",
      "74   512.416247  115.115197  483.587231  134.334541  495.817722  136.081754   \n",
      "75   393.605756  245.282573  420.687559  240.914541  424.181985  226.063229   \n",
      "76   515.037067  184.130115  476.598378  185.877328  488.828870  192.866180   \n",
      "77   383.122477  249.650606  411.951493  240.914541  416.319526  226.063229   \n",
      "78   545.613296  288.962901  540.371657  248.777000  519.405099  252.271426   \n",
      "81    71.244938   23.386509   62.508873   62.698804   71.244938   67.940443   \n",
      "83   487.955263  327.401589  516.784280  307.308639  504.553788  301.193393   \n",
      "84   363.903133  302.066999  340.315756  294.204540  346.431002  319.539130   \n",
      "85   383.122477  168.405197  413.698706  168.405197  403.215428  143.944213   \n",
      "86   270.427232  144.817820  284.404937  152.680279  290.520183  132.587328   \n",
      "87   434.665264   94.148640  417.193133   94.148640  417.193133  104.631918   \n",
      "89   191.802642  311.676671  219.758052  260.133885  169.962478  256.639459   \n",
      "92   336.821330  236.546508  358.661494  208.591098  347.304609  207.717492   \n",
      "93   425.055592  260.133885  438.159690  234.799295  414.572313  238.293721   \n",
      "94   441.654116   81.918148  419.813952   82.791755  420.687559   84.538968   \n",
      "95   370.018379  126.472082  378.754444  130.840115  378.754444  119.483230   \n",
      "96   366.523953  193.739787  359.535100  181.509295  380.501658  182.382902   \n",
      "97   329.832477  149.185853  329.832477  154.427492  340.315756  151.806672   \n",
      "98   486.208050  152.680279  480.092804  133.460935  461.747067  146.565033   \n",
      "105  191.802642  240.040934  183.066577  234.799295  199.665101  234.799295   \n",
      "106  284.404937  308.182245  335.074117  282.847655  312.360346  262.754704   \n",
      "107  448.642969  209.464705  420.687559  203.349459  432.044444  219.074377   \n",
      "108  425.929198  236.546508  413.698706  221.695196  439.906903  224.316016   \n",
      "109  569.200673  301.193393  544.739689  254.018639  559.591001  272.364376   \n",
      "110  529.014771  255.765852  504.553788  246.156180  537.750837  241.788147   \n",
      "112  453.884608  255.765852  461.747067  247.029786  466.115100  233.925688   \n",
      "114  466.115100  129.092902  459.126247  133.460935  480.092804  140.449787   \n",
      "115  534.256411  337.011261  571.821492  321.286343  553.475755  302.940606   \n",
      "117  241.598216  133.460935  266.932806  126.472082  252.955101  114.241591   \n",
      "118  256.449527  287.215688  261.691166  274.111590  240.724609  269.743557   \n",
      "119  481.840018  175.394049  476.598378  198.107820  506.301001  204.223065   \n",
      "120  250.334281  233.052082  238.103790  244.408967  257.323134  243.535360   \n",
      "121  497.564935  138.702574  489.702477  156.174705  509.795427  157.048312   \n",
      "122  181.319364  145.691426  211.895593  145.691426  204.033134  124.724869   \n",
      "123  579.683951  147.438640  547.360509  165.784377  559.591001  182.382902   \n",
      "124  611.133787  322.159950  593.661656  295.951753  567.453460  309.055852   \n",
      "125  499.312149  346.620933  550.854935  334.390442  529.888378  315.171098   \n",
      "\n",
      "                                                                             \\\n",
      "        leftHip                rightHip                tailBase               \n",
      "              x           y           x           y           x           y   \n",
      "26   258.196740  218.200770  236.356576  217.327164  264.311986  194.613393   \n",
      "27   348.178215  201.602246  361.282313  214.706344  335.074117  218.200770   \n",
      "28   265.185593  210.338311  303.624281  209.464705  293.141002  226.063229   \n",
      "31   294.888215  212.959131  316.728379  217.327164  303.624281  219.947983   \n",
      "32   296.635429  118.609623  320.222805  125.598476  309.739527  151.806672   \n",
      "35   162.973626  219.947983  160.352806  209.464705  197.917888  233.052082   \n",
      "36   142.880675  122.977656  178.698544  130.840115  164.720839  184.130115   \n",
      "37   310.613133  299.446180  317.601986  308.182245  270.427232  287.215688   \n",
      "38   131.523790  195.487000  148.995921  192.866180  170.836085  219.074377   \n",
      "39   121.914118  152.680279  138.512643  150.933066  149.869528  171.899623   \n",
      "40   141.133462  248.777000  194.423462  241.788147  183.940183  276.732409   \n",
      "41   300.129855  261.881098  263.438380  274.985196  272.174445  257.513065   \n",
      "42   301.003461  287.215688  296.635429  301.193393  240.724609  264.501918   \n",
      "43   431.170838  274.111590  418.940346  299.446180  388.364116  269.743557   \n",
      "44   204.906741  248.777000  198.791495  241.788147  223.252478  240.914541   \n",
      "45   111.430839  156.174705  128.902971  155.301099  134.144610  166.657984   \n",
      "46   102.694774  184.130115  128.902971  185.877328  140.259856  205.096672   \n",
      "47   171.709692  240.914541  207.527560  241.788147  198.791495  259.260278   \n",
      "48   452.137395  254.892245  480.092804  246.156180  485.334444  262.754704   \n",
      "49   267.806412  261.881098  247.713462  281.100442  234.609363  239.167328   \n",
      "50   151.616741   83.665361  165.594446   56.583558  183.066577   66.193230   \n",
      "51   114.925266   61.825197  149.869528   43.479460  113.178053   26.880935   \n",
      "52   385.743297  171.026016  390.111330  192.866180  354.293461  186.750934   \n",
      "53   465.241493  191.118967  433.791657  157.048312  336.821330  143.070607   \n",
      "54   272.174445  252.271426  231.988544  249.650606  240.724609  226.063229   \n",
      "55   186.561003  316.918311  197.044282  304.687819  223.252478  308.182245   \n",
      "56   196.170675  315.171098  171.709692  297.698966  199.665101  281.974049   \n",
      "59   252.955101  148.312246  246.839855  183.256508  228.494117  158.795525   \n",
      "64   296.635429  216.453557  285.278543  208.591098  314.107560  213.832737   \n",
      "65   277.416084  202.475852  286.152150  189.371754  301.877068  207.717492   \n",
      "72   304.497887  244.408967  272.174445  240.914541  299.256248  217.327164   \n",
      "74   215.390019  245.282573  177.824937  248.777000  195.297068  252.271426   \n",
      "75   215.390019  268.869950  167.341659  262.754704  191.802642  257.513065   \n",
      "76   183.066577  246.156180  199.665101  240.040934  214.516413  245.282573   \n",
      "77   165.594446  225.189623  195.297068  223.442410  188.308216  238.293721   \n",
      "78   227.620511  260.133885  203.159527  264.501918  212.769200  247.029786   \n",
      "81   125.408544  251.397819  167.341659  262.754704  179.572151  262.754704   \n",
      "83   195.297068  175.394049  212.769200  164.037164  219.758052  183.256508   \n",
      "84   238.977396  181.509295  221.505265  166.657984  244.219035  150.933066   \n",
      "85   239.851003  215.579951  268.680019  240.040934  230.241331  250.524213   \n",
      "86   214.516413  132.587328  240.724609  128.219295  237.230183  156.174705   \n",
      "87   259.943953  221.695196  252.955101  231.304869  235.482970  230.431262   \n",
      "89   258.196740  281.974049  289.646576  264.501918  303.624281  280.226835   \n",
      "92   240.724609  207.717492  263.438380  217.327164  244.219035  219.074377   \n",
      "93   231.114937  208.591098  249.460675  217.327164  235.482970  216.453557   \n",
      "94   226.746904  271.490770  208.401167  273.237983  242.471822  254.892245   \n",
      "95   301.003461  299.446180  309.739527  284.594868  286.152150  287.215688   \n",
      "96   334.200510  203.349459  322.843625  191.992574  344.683789  203.349459   \n",
      "97   300.129855  206.843885  282.657724  204.223065  291.393789  199.855033   \n",
      "98   351.672641  199.855033  334.200510  203.349459  338.568543  198.107820   \n",
      "105  270.427232  295.951753  277.416084  281.974049  314.981166  301.193393   \n",
      "106  143.754282  236.546508  168.215265  237.420114  153.363954  252.271426   \n",
      "107  106.189200  267.122737  144.627888  264.501918  127.155757  274.985196   \n",
      "108  148.122315  276.732409  120.166905  270.617163  174.330511  290.710114   \n",
      "109  140.259856  159.669131  156.858380  165.784377  159.479200  199.855033   \n",
      "110  128.902971  189.371754  158.605593  181.509295  146.375102  202.475852   \n",
      "112  167.341659  259.260278  191.802642  265.375524  156.858380  269.743557   \n",
      "114  210.148380  249.650606  194.423462  262.754704  177.824937  246.156180   \n",
      "115  491.449690  173.646836  509.795427  171.899623  501.932968  198.107820   \n",
      "117  203.159527  180.635689  243.345429  182.382902  249.460675  199.855033   \n",
      "118  231.114937  157.921918  224.999691  142.197000  256.449527  147.438640   \n",
      "119  333.326904  191.992574  301.877068  210.338311  293.141002  173.646836   \n",
      "120  343.810182  177.141262  325.464445  156.174705  357.787887  150.933066   \n",
      "121  394.479362  252.271426  373.512805  273.237983  359.535100  254.892245   \n",
      "122  156.858380  200.728639  162.100020  185.003721  174.330511  191.118967   \n",
      "123  132.397397  166.657984  152.490347  150.933066  152.490347  164.037164   \n",
      "124  235.482970  185.877328  233.735757  159.669131  252.955101  178.888475   \n",
      "125  493.196903  238.293721  450.390182  230.431262  457.379034  215.579951   \n",
      "26   364.776740  240.040934  394.479362  236.546508  401.468215  243.535360   \n",
      "27   418.940346  219.074377  397.100182  222.568803  396.226575  212.085524   \n",
      "28   349.051822  133.460935  373.512805  135.208148  363.029526  159.669131   \n",
      "31   383.996084  227.810442  378.754444  240.914541  333.326904  231.304869   \n",
      "32   329.832477  187.624541  359.535100  189.371754  362.155920  215.579951   \n",
      "35   332.453297  203.349459  361.282313  203.349459  353.419854  223.442410   \n",
      "36   310.613133  269.743557  270.427232  258.386672  382.248871  252.271426   \n",
      "37   346.431002  249.650606  345.557395  241.788147  373.512805  240.914541   \n",
      "38   263.438380  271.490770  217.137232  262.754704  249.460675  257.513065   \n",
      "39   216.263626  277.606016  205.780347  262.754704  256.449527  270.617163   \n",
      "40   194.423462  222.568803  171.709692  231.304869  213.642806  230.431262   \n",
      "41   492.323296  262.754704  529.888378  260.133885  537.750837  283.721262   \n",
      "42   250.334281  245.282573  302.750674  256.639459  405.836248  248.777000   \n",
      "43   519.405099  272.364376  481.840018  274.111590  382.248871  252.271426   \n",
      "44   321.970019  273.237983  342.062969  273.237983  364.776740  276.732409   \n",
      "45   509.795427  256.639459  485.334444  262.754704  465.241493  276.732409   \n",
      "46   384.869690  289.836508  384.869690  268.869950  418.940346  280.226835   \n",
      "47   597.156082  159.669131  558.717394  154.427492  560.464607  198.107820   \n",
      "48   609.386574  143.070607  596.282476  163.163557  589.293623  175.394049   \n",
      "49   142.880675  288.962901  145.501495  254.018639  161.226413  272.364376   \n",
      "50   265.185593  153.553885  270.427232  140.449787  294.888215  151.806672   \n",
      "51   249.460675  152.680279  254.702314  132.587328  280.910511  136.081754   \n",
      "52   481.840018  136.955361  471.356739  150.933066  443.401329  125.598476   \n",
      "53   510.669034  248.777000  534.256411  232.178475  527.267558  143.944213   \n",
      "54   503.680181  241.788147  504.553788  216.453557  523.773132  222.568803   \n",
      "55   241.598216  265.375524  235.482970  252.271426  245.966248  239.167328   \n",
      "56   303.624281  249.650606  325.464445  273.237983  285.278543  274.985196   \n",
      "59   328.085264  163.163557  382.248871  174.520443  345.557395  200.728639   \n",
      "64   466.115100  244.408967  419.813952  251.397819  363.029526  247.903393   \n",
      "65   238.103790  226.936836  262.564773  234.799295  235.482970  244.408967   \n",
      "72   377.007231  318.665524  414.572313  302.066999  434.665264  317.791917   \n",
      "74   463.494280  217.327164  467.862313  236.546508  447.769362  231.304869   \n",
      "75   501.932968  271.490770  501.059362  257.513065  529.014771  250.524213   \n",
      "76   432.918051  234.799295  450.390182  248.777000  424.181985  261.007491   \n",
      "77   435.538870  243.535360  462.620673  241.788147  457.379034  252.271426   \n",
      "78   473.103952  272.364376  450.390182  272.364376  425.055592  255.765852   \n",
      "81    50.278381  184.130115   60.761659  182.382902   72.118545  203.349459   \n",
      "83   536.877230  259.260278  506.301001  249.650606  516.784280  219.074377   \n",
      "84   291.393789  306.435032  287.899363  328.275196  269.553625  323.033557   \n",
      "85   460.873460  166.657984  462.620673  145.691426  483.587231  148.312246   \n",
      "86   357.787887  169.278803  363.029526  149.185853  377.007231  159.669131   \n",
      "87   425.929198  122.977656  431.170838  132.587328  403.215428  201.602246   \n",
      "89   210.148380  271.490770  180.445757  269.743557  193.549855  251.397819   \n",
      "92   385.743297  216.453557  366.523953  219.947983  370.891985  212.085524   \n",
      "93   423.308379  249.650606  382.248871  248.777000  374.386412  229.557655   \n",
      "94   385.743297  133.460935  385.743297  134.334541  378.754444  143.944213   \n",
      "95   385.743297  166.657984  409.330674  167.531590  393.605756  178.888475   \n",
      "96   365.650346  215.579951  378.754444  216.453557  377.007231  223.442410   \n",
      "97   364.776740  209.464705  360.408707  200.728639  303.624281  221.695196   \n",
      "98   451.263788  236.546508  433.791657  253.145032  399.721002  264.501918   \n",
      "105  160.352806  254.018639  205.780347  261.007491  176.077724  259.260278   \n",
      "106  436.412477  306.435032  426.802805  274.111590  464.367887  283.721262   \n",
      "107  354.293461  234.799295  365.650346  248.777000  328.085264  247.029786   \n",
      "108  393.605756  250.524213  433.791657  261.007491  392.732149  259.260278   \n",
      "109  482.713624  274.985196  482.713624  295.951753  449.516575  287.215688   \n",
      "110  503.680181  274.985196  543.866083  276.732409  522.899525  282.847655   \n",
      "112  503.680181  258.386672  515.910673  247.029786  527.267558  259.260278   \n",
      "114  446.895755  213.832737  473.103952  217.327164  462.620673  229.557655   \n",
      "115  600.650509  288.089294  561.338214  286.342081  570.074279  275.858803   \n",
      "117  302.750674  133.460935  288.772970  119.483230  314.981166  123.851263   \n",
      "118  298.382642  226.936836  270.427232  219.947983  305.371494  205.096672   \n",
      "119  485.334444  267.996344  522.025919  272.364376  494.070509  294.204540   \n",
      "120  290.520183  302.940606  308.865920  280.226835  318.475592  309.929458   \n",
      "121  485.334444  212.085524  505.427394  213.832737  490.576083  234.799295   \n",
      "122  277.416084  185.877328  264.311986  173.646836  285.278543  165.784377   \n",
      "123  496.691329  220.821590  505.427394  243.535360  495.817722  232.178475   \n",
      "124  540.371657  306.435032  515.910673  316.918311  523.773132  299.446180   \n",
      "125  586.672804  318.665524  556.970181  309.929458  560.464607  294.204540   \n",
      "\n",
      "                              x_locatin  y_location  \n",
      "        tailEnd                                      \n",
      "              x           y                          \n",
      "26   301.877068  185.877328  259.070347  215.579951  \n",
      "27   354.293461  251.397819  355.167068  209.464705  \n",
      "28   363.903133  238.293721  315.854773  215.579951  \n",
      "31   255.575921  268.869950  302.313871  219.074377  \n",
      "32   325.464445  221.695196  312.797150  153.990689  \n",
      "35   334.200510  291.583721  219.321249  174.083639  \n",
      "36   204.906741  321.286343  181.319364  166.221180  \n",
      "37   129.776577  258.386672  304.061084  274.985196  \n",
      "38   216.263626  227.810442  163.847233  176.704459  \n",
      "39   185.687396  236.546508  143.754282  140.449787  \n",
      "40   286.152150  293.330934  208.401167  241.788147  \n",
      "41   287.025756  241.788147  307.118707  260.133885  \n",
      "42   162.100020  201.602246  304.934691  282.410852  \n",
      "43   312.360346  203.349459  437.286083  262.317901  \n",
      "44   312.360346  286.342081  206.653954  223.442410  \n",
      "45   175.204118  278.479622  123.661331  162.726754  \n",
      "46   211.895593  277.606016  149.432724  180.635689  \n",
      "47   292.267396  270.617163  227.620511  240.914541  \n",
      "48   474.851165  299.446180  464.367887  254.892245  \n",
      "49   253.828707  156.174705  266.932806  230.868065  \n",
      "50   221.505265   96.769460  153.800757   55.709952  \n",
      "51   117.546085   76.676509  132.834200   63.572411  \n",
      "52   290.520183  134.334541  372.202395  176.704459  \n",
      "53   414.572313  152.680279  433.791657  185.877328  \n",
      "54   249.460675  136.955361  246.403052  231.741672  \n",
      "55   207.527560  294.204540  161.226413  284.158065  \n",
      "56   296.635429  222.568803  173.020101  277.169213  \n",
      "59   265.185593  109.873558  262.564773  153.990689  \n",
      "64   374.386412  237.420114  308.865920  197.234213  \n",
      "65   377.007231  234.799295  296.635429  197.234213  \n",
      "72   374.386412  210.338311  309.302724  254.455442  \n",
      "74   260.817560  264.501918  231.114937  221.695196  \n",
      "75   197.917888  233.052082  194.423462  265.375524  \n",
      "76   296.635429  289.836508  217.574036  217.327164  \n",
      "77   274.795265  285.468475  226.746904  209.027901  \n",
      "78   238.977396  252.271426  252.081494  263.628311  \n",
      "81   237.230183  257.513065  173.893708  234.799295  \n",
      "83   282.657724  251.397819  218.447642  170.589213  \n",
      "84   345.557395  161.416344  249.460675  165.784377  \n",
      "85   275.668871  320.412737  249.897478  240.477737  \n",
      "86   274.795265  236.546508  229.804527  141.323394  \n",
      "87   245.966248  221.695196  276.979281  210.775115  \n",
      "89   363.029526  264.501918  292.704199  231.741672  \n",
      "92   228.494117  252.271426  252.518298  215.143147  \n",
      "93   209.274773  235.672901  248.587068  211.211918  \n",
      "94   336.821330  254.892245  261.254363  267.122737  \n",
      "95   207.527560  274.985196  344.246986  271.053967  \n",
      "96   387.490510  224.316016  336.821330  206.407082  \n",
      "97   314.107560  205.096672  276.105675  205.970279  \n",
      "98   328.085264  173.646836  342.062969  209.027901  \n",
      "105  441.654116  295.078147  316.728379  264.501918  \n",
      "106  239.851003  302.066999  187.434610  256.202655  \n",
      "107  293.141002  331.769622  193.549855  246.156180  \n",
      "108  355.167068  350.988966  215.390019  219.511180  \n",
      "109  182.192970  267.996344  151.616741  173.646836  \n",
      "110  166.468052  261.881098  144.627888  180.198885  \n",
      "112  254.702314  329.148802  208.837970  257.513065  \n",
      "114  143.754282  236.546508  214.953216  244.408967  \n",
      "115  422.434772  269.743557  462.183870  191.992574  \n",
      "117  335.074117  195.487000  275.668871  161.416344  \n",
      "118  359.535100  163.163557  259.507150  146.128230  \n",
      "119  240.724609  117.736017  302.750674  182.819705  \n",
      "120  454.758214  175.394049  344.246986  165.784377  \n",
      "121  266.932806  288.089294  384.432887  256.202655  \n",
      "122  294.888215  191.992574  174.767315  165.784377  \n",
      "123  229.367724  206.843885  145.938298  151.806672  \n",
      "124  338.568543  247.029786  255.139117  190.682164  \n",
      "125  373.512805  171.899623  434.228460  233.488885  \n",
      "26   338.568543  261.007491  369.581576  230.868065  \n",
      "27   389.237723  216.453557  407.146657  222.568803  \n",
      "28   370.891985  227.810442  359.535100  148.749049  \n",
      "31   352.546248  223.442410  390.111330  220.384787  \n",
      "32   422.434772  245.282573  370.018379  189.371754  \n",
      "35   305.371494  243.535360  334.200510  196.797410  \n",
      "36   282.657724  252.271426  297.945838  238.730524  \n",
      "37   466.115100  232.178475  354.293461  244.408967  \n",
      "38   252.081494  245.282573  228.930921  260.570688  \n",
      "39   280.910511  264.501918  199.665101  264.938721  \n",
      "40   282.657724  252.271426  193.113052  229.557655  \n",
      "41   475.724772  320.412737  506.737804  272.364376  \n",
      "42   389.237723  216.453557  289.209773  268.433147  \n",
      "43   282.657724  252.271426  497.128132  250.087409  \n",
      "44   448.642969  266.249131  331.579691  268.433147  \n",
      "45   358.661494  302.940606  449.516575  243.535360  \n",
      "46   523.773132  292.457327  396.226575  264.501918  \n",
      "47   489.702477  296.825360  552.602148  160.979541  \n",
      "48   527.267558  294.204540  568.327066  203.786262  \n",
      "49   230.241331  279.353229  148.122315  244.845770  \n",
      "50   389.237723  159.669131  307.118707  129.966508  \n",
      "51   383.996084  168.405197  287.025756  151.369869  \n",
      "52   349.925428  119.483230  432.918051  149.622656  \n",
      "53   161.226413  272.364376  506.301001  316.481507  \n",
      "54   537.750837  141.323394  490.576083  191.118967  \n",
      "55   356.914281  255.765852  255.575921  264.501918  \n",
      "56   205.780347  280.226835  295.325019  235.672901  \n",
      "59   249.460675  211.211918  327.648461  166.221180  \n",
      "64   230.241331  279.353229  424.618788  188.934951  \n",
      "65   245.966248  285.468475  239.851003  225.189623  \n",
      "72   566.579853  309.929458  418.940346  264.938721  \n",
      "74   354.293461  274.985196  434.228460  192.429377  \n",
      "75   509.795427  233.052082  462.183870  251.397819  \n",
      "76   311.486740  279.353229  418.940346  221.258393  \n",
      "77   356.914281  283.721262  415.445920  250.087409  \n",
      "78   313.233953  261.007491  427.676411  258.386672  \n",
      "81   155.984774  272.364376   81.728217  149.622656  \n",
      "83   471.356739  142.197000  494.507313  227.810442  \n",
      "84   204.033134  251.397819  289.646576  288.526098  \n",
      "85   540.371657  210.338311  463.494280  166.221180  \n",
      "86   481.840018  187.624541  372.639199  156.174705  \n",
      "87   331.579691  233.052082  386.616903  164.037164  \n",
      "89   213.642806  252.271426  207.527560  264.065114  \n",
      "92   365.650346  201.602246  360.408707  220.384787  \n",
      "93   302.750674  230.431262  375.260018  240.040934  \n",
      "94   349.051822  215.579951  391.858543  144.817820  \n",
      "95   380.501658  224.316016  388.800920  165.784377  \n",
      "96   377.880838  255.765852  375.260018  217.763967  \n",
      "97   230.241331  279.353229  353.419854  189.371754  \n",
      "98   301.877068  284.594868  402.341821  211.211918  \n",
      "105  161.226413  331.769622  178.261741  269.306754  \n",
      "106  534.256411  281.974049  412.388297  281.537245  \n",
      "107  233.735757  226.063229  348.615018  232.178475  \n",
      "108  293.141002  287.215688  378.317641  249.650606  \n",
      "109  453.011001  269.743557  491.886493  272.364376  \n",
      "110  406.709854  323.907163  485.771247  263.628311  \n",
      "112  534.256411  300.319786  503.243378  259.697081  \n",
      "114  459.126247  287.215688  462.183870  202.039049  \n",
      "115  504.553788  261.007491  563.085427  290.710114  \n",
      "117  409.330674  136.081754  318.912396  122.977656  \n",
      "118  265.185593  152.680279  273.921658  218.637574  \n",
      "119  390.984936  312.550278  472.230345  254.892245  \n",
      "120  418.940346  340.505688  328.085264  284.158065  \n",
      "121  473.103952  264.501918  488.392067  196.797410  \n",
      "122  380.501658  128.219295  262.564773  156.611508  \n",
      "123  376.133625  254.018639  479.656001  203.349459  \n",
      "124  466.115100  220.821590  535.566821  271.927573  \n",
      "125  506.301001  293.330934  548.670919  308.182245  \n"
     ]
    }
   ],
   "source": [
    "rows = len(df) #getting the number of data examples that we have\n",
    "\n",
    "# if we want to sample the data in order to mix it\n",
    "#df = df.sample(frac = 1.00)\n",
    "\n",
    "df = df.iloc[: , 3:]\n",
    "#print(df)\n",
    "\n",
    "#getting rid of the possible NaN values\n",
    "th = 1\n",
    "df = df.dropna(axis = 0)\n",
    "df.fillna(value = 200.000)\n",
    "\n",
    "rows_na = len(df)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"{} rows were eliminated due to issues related to NaN values\".format(rows - rows_na))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "mouse1 = df.xs('mouse1', level=1, axis=1)\n",
    "mouse1 = mouse1.dropna(axis = 0)\n",
    "mouse2 = df.xs('mouse2', level=1, axis=1)\n",
    "mouse2 = mouse2.dropna(axis = 0)\n",
    "\n",
    "# print(mouse1.shape)\n",
    "# print(mouse2.shape)\n",
    "\n",
    "# print(\"Mouse 1\")\n",
    "# print(mouse1.describe)\n",
    "# print(\"Mouse 2\")\n",
    "# print(mouse2.describe)\n",
    "\n",
    "\n",
    "# we add as rows the mouse2 samples' data taken in pictures where more than one mice were found\n",
    "#df = pd.concat([mouse1, mouse2], axis=0)\n",
    "df = mouse1.append(mouse2)\n",
    "#print(df)\n",
    "\n",
    "# we create one dataset per axis with data related to its own axis\n",
    "df_x = df.xs('x', level=2, axis=1)\n",
    "df_y = df.xs('y', level=2, axis=1)\n",
    "\n",
    "# we calculate the average location of the mice in both axis\n",
    "x_cg = (df_x.xs('topleft', level=1, axis=1) + df_x.xs('rightdown', level=1, axis=1)) / 2\n",
    "y_cg = (df_y.xs('topleft', level=1, axis=1) + df_y.xs('rightdown', level=1, axis=1)) / 2\n",
    "\n",
    "# renaming the columns of the dataframes\n",
    "x_cg.rename(columns = {'annotation':'x_location'}, inplace = True)\n",
    "y_cg.rename(columns = {'annotation':'y_location'}, inplace = True)\n",
    "\n",
    "# we get rid of the data used for calculating the average location of the mice in both axis\n",
    "df = cleaning(df)\n",
    "df_x = cleaning(df_x)\n",
    "df_y = cleaning(df_y)\n",
    "\n",
    "# we add to df the calculated average location of the mice in both axis\n",
    "df = df.assign(x_locatin = x_cg)\n",
    "df = df.assign(y_location = y_cg)\n",
    "\n",
    "#print(df_x)\n",
    "# df_x is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "#print(df_y)\n",
    "# df_y is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "print(df)\n",
    "# df is a dataset made up of 187 rows and 16 columns ( 7 attributes per axis + one location per axis)\n",
    "\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, the fed datasets will be divided in training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = 0.2\n",
    "\n",
    "# x_cg and y_cg will be the respective results for the testing and training of the 7 atributes fed Neural Network\n",
    "# y_2d will be the respective result for the testing and training of the 14 atributes fed Neural Network\n",
    "\n",
    "y_2d = pd.concat([x_cg, y_cg], axis = 1)\n",
    "\n",
    "in_x_train, in_x_test, out_x_train, out_x_test = train_test_split(df_x, x_cg, test_size = coef)\n",
    "in_y_train, in_y_test, out_y_train,  out_y_test = train_test_split(df_y, y_cg, test_size = coef)\n",
    "in_2d_train, in_2d_test, out_2d_train, out_2d_test = train_test_split(df['annotation'], y_2d, test_size = coef)\n",
    "\n",
    "# just checking if the split is done properly according to the established 0.2 coefficient \n",
    "\n",
    "# print(in_x_test.shape)\n",
    "# print(in_y_train.shape)\n",
    "# print(in_2d_train.shape)\n",
    "# print(in_2d_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will print some of the useful datasets in order to see their structure before being fed to the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nose</th>\n",
       "      <th>leftear</th>\n",
       "      <th>rightear</th>\n",
       "      <th>leftHip</th>\n",
       "      <th>rightHip</th>\n",
       "      <th>tailBase</th>\n",
       "      <th>tailEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>242.471822</td>\n",
       "      <td>265.185593</td>\n",
       "      <td>258.196740</td>\n",
       "      <td>343.810182</td>\n",
       "      <td>325.464445</td>\n",
       "      <td>357.787887</td>\n",
       "      <td>454.758214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>90.464282</td>\n",
       "      <td>100.073954</td>\n",
       "      <td>107.936413</td>\n",
       "      <td>151.616741</td>\n",
       "      <td>165.594446</td>\n",
       "      <td>183.066577</td>\n",
       "      <td>221.505265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>320.222805</td>\n",
       "      <td>302.750674</td>\n",
       "      <td>322.843625</td>\n",
       "      <td>294.888215</td>\n",
       "      <td>316.728379</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>255.575921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>200.538708</td>\n",
       "      <td>193.549855</td>\n",
       "      <td>211.021986</td>\n",
       "      <td>171.709692</td>\n",
       "      <td>207.527560</td>\n",
       "      <td>198.791495</td>\n",
       "      <td>292.267396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56.393627</td>\n",
       "      <td>93.958708</td>\n",
       "      <td>100.073954</td>\n",
       "      <td>111.430839</td>\n",
       "      <td>128.902971</td>\n",
       "      <td>134.144610</td>\n",
       "      <td>175.204118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotation                                                              \\\n",
       "           nose     leftear    rightear     leftHip    rightHip    tailBase   \n",
       "120  242.471822  265.185593  258.196740  343.810182  325.464445  357.787887   \n",
       "50    90.464282  100.073954  107.936413  151.616741  165.594446  183.066577   \n",
       "31   320.222805  302.750674  322.843625  294.888215  316.728379  303.624281   \n",
       "47   200.538708  193.549855  211.021986  171.709692  207.527560  198.791495   \n",
       "45    56.393627   93.958708  100.073954  111.430839  128.902971  134.144610   \n",
       "\n",
       "                 \n",
       "        tailEnd  \n",
       "120  454.758214  \n",
       "50   221.505265  \n",
       "31   255.575921  \n",
       "47   292.267396  \n",
       "45   175.204118  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>344.246986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>153.800757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>302.313871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>227.620511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>123.661331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_location\n",
       "120  344.246986\n",
       "50   153.800757\n",
       "31   302.313871\n",
       "47   227.620511\n",
       "45   123.661331"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>219.758052</td>\n",
       "      <td>86.286181</td>\n",
       "      <td>243.345429</td>\n",
       "      <td>108.999951</td>\n",
       "      <td>245.092642</td>\n",
       "      <td>86.286181</td>\n",
       "      <td>265.185593</td>\n",
       "      <td>153.553885</td>\n",
       "      <td>270.427232</td>\n",
       "      <td>140.449787</td>\n",
       "      <td>294.888215</td>\n",
       "      <td>151.806672</td>\n",
       "      <td>389.237723</td>\n",
       "      <td>159.669131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>383.122477</td>\n",
       "      <td>168.405197</td>\n",
       "      <td>413.698706</td>\n",
       "      <td>168.405197</td>\n",
       "      <td>403.215428</td>\n",
       "      <td>143.944213</td>\n",
       "      <td>460.873460</td>\n",
       "      <td>166.657984</td>\n",
       "      <td>462.620673</td>\n",
       "      <td>145.691426</td>\n",
       "      <td>483.587231</td>\n",
       "      <td>148.312246</td>\n",
       "      <td>540.371657</td>\n",
       "      <td>210.338311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>118.419692</td>\n",
       "      <td>37.364214</td>\n",
       "      <td>155.111167</td>\n",
       "      <td>65.319624</td>\n",
       "      <td>158.605593</td>\n",
       "      <td>57.457165</td>\n",
       "      <td>162.973626</td>\n",
       "      <td>219.947983</td>\n",
       "      <td>160.352806</td>\n",
       "      <td>209.464705</td>\n",
       "      <td>197.917888</td>\n",
       "      <td>233.052082</td>\n",
       "      <td>334.200510</td>\n",
       "      <td>291.583721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>499.312149</td>\n",
       "      <td>346.620933</td>\n",
       "      <td>550.854935</td>\n",
       "      <td>334.390442</td>\n",
       "      <td>529.888378</td>\n",
       "      <td>315.171098</td>\n",
       "      <td>586.672804</td>\n",
       "      <td>318.665524</td>\n",
       "      <td>556.970181</td>\n",
       "      <td>309.929458</td>\n",
       "      <td>560.464607</td>\n",
       "      <td>294.204540</td>\n",
       "      <td>506.301001</td>\n",
       "      <td>293.330934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>466.988706</td>\n",
       "      <td>312.550278</td>\n",
       "      <td>418.940346</td>\n",
       "      <td>274.111590</td>\n",
       "      <td>417.193133</td>\n",
       "      <td>284.594868</td>\n",
       "      <td>301.003461</td>\n",
       "      <td>287.215688</td>\n",
       "      <td>296.635429</td>\n",
       "      <td>301.193393</td>\n",
       "      <td>240.724609</td>\n",
       "      <td>264.501918</td>\n",
       "      <td>162.100020</td>\n",
       "      <td>201.602246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nose                 leftear                rightear              \\\n",
       "              x           y           x           y           x           y   \n",
       "50   219.758052   86.286181  243.345429  108.999951  245.092642   86.286181   \n",
       "85   383.122477  168.405197  413.698706  168.405197  403.215428  143.944213   \n",
       "35   118.419692   37.364214  155.111167   65.319624  158.605593   57.457165   \n",
       "125  499.312149  346.620933  550.854935  334.390442  529.888378  315.171098   \n",
       "42   466.988706  312.550278  418.940346  274.111590  417.193133  284.594868   \n",
       "\n",
       "        leftHip                rightHip                tailBase              \\\n",
       "              x           y           x           y           x           y   \n",
       "50   265.185593  153.553885  270.427232  140.449787  294.888215  151.806672   \n",
       "85   460.873460  166.657984  462.620673  145.691426  483.587231  148.312246   \n",
       "35   162.973626  219.947983  160.352806  209.464705  197.917888  233.052082   \n",
       "125  586.672804  318.665524  556.970181  309.929458  560.464607  294.204540   \n",
       "42   301.003461  287.215688  296.635429  301.193393  240.724609  264.501918   \n",
       "\n",
       "        tailEnd              \n",
       "              x           y  \n",
       "50   389.237723  159.669131  \n",
       "85   540.371657  210.338311  \n",
       "35   334.200510  291.583721  \n",
       "125  506.301001  293.330934  \n",
       "42   162.100020  201.602246  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_2d_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_location</th>\n",
       "      <th>y_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>307.118707</td>\n",
       "      <td>129.966508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>463.494280</td>\n",
       "      <td>166.221180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>219.321249</td>\n",
       "      <td>174.083639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>548.670919</td>\n",
       "      <td>308.182245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>304.934691</td>\n",
       "      <td>282.410852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_location  y_location\n",
       "50   307.118707  129.966508\n",
       "85   463.494280  166.221180\n",
       "35   219.321249  174.083639\n",
       "125  548.670919  308.182245\n",
       "42   304.934691  282.410852"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2d_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first model will be ran and its name will be \"THE AXIS DEPENDENT MODEL\". This model is caracterized by taking the 14 attributes as input, and giving two outputs as both coordinates of the location of the mouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, the Neural Network model will be created by using the Tensorflow library. Then, we have to keep building up the Neural Network by establishing some other parameters, and finally, the model will be ready for the training stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"THE DEPENDENT MODEL\" the next datasets will be used: in_2d_train, in_2d_test, out_2d_train, out_2d_test\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def train(df_in, df_out, neurons, output, epoch):\n",
    "    \n",
    "    input_shape = [df_in.shape[1]]\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=neurons, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(units=neurons, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=output)\n",
    "    ])\n",
    "    \n",
    "    # printing a summary in order to check if it works\n",
    "    model.summary()\n",
    "\n",
    "    # We will use the adam optimizer due to the fact that it behaves well overally \n",
    "\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    batchs = int(rows / 30)\n",
    "\n",
    "\n",
    "    losses = model.fit(\n",
    "                        df_in, df_out,\n",
    "                        batch_size = batchs,\n",
    "                        epochs = epoch\n",
    "                    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return [model, losses]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the train() function has been created, we need to create the function that will run the simulations with the different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df_in, df_out, df_in_test, df_out_test,  neurons, output, epoch):\n",
    "    results = train(df_in, df_out, neurons, output, epoch)\n",
    "    model = results[0]\n",
    "\n",
    "    pred = pd.DataFrame(model.predict(df_in_test)) \n",
    "\n",
    "    error = pred.values - df_out_test.values\n",
    "    error = pd.DataFrame(error)\n",
    "    print(\"Printing\")\n",
    "    print(error)\n",
    "    \n",
    "    errors = [round(abs(error.iloc[:, x].mean()), 2) for x in range(df_out_test.shape[1])]\n",
    "    \n",
    "    for i in range(len(errors)):\n",
    "        print(\"The average error for the {}-axis was: \".format(i), errors[i])\n",
    "    losses = results[1]\n",
    "    \n",
    "    # print(loss_df)\n",
    "    return [errors, losses]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just need to invoke the function that runs the simulations with the model parameters that we want to build and the dataset that we want to feed.\n",
    "\n",
    "This way, we will run a while with one simulation with increasing number of neurons on each loop, until the error gets lower than a threshold. Hence, we will get the minimum neuron number per layer, for a valid a model which ensures an error upper-bounded by a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_631\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1893 (Dense)          (None, 32)                480       \n",
      "                                                                 \n",
      " dense_1894 (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1895 (Dense)          (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,602\n",
      "Trainable params: 1,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 160.6404\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 57.8660\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 32.2697\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 17.6165\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 14.0025\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.5004\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.1210\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0768\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1461\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5496\n",
      "Model: \"sequential_631\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1893 (Dense)          (None, 32)                480       \n",
      "                                                                 \n",
      " dense_1894 (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1895 (Dense)          (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,602\n",
      "Trainable params: 1,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0  -22.226361  -9.022857\n",
      "1   -6.620551  -8.655695\n",
      "2  -14.690646 -18.302260\n",
      "3  -15.441012  -7.393498\n",
      "4  -17.436884  11.214607\n",
      "5   -8.062453  -6.004416\n",
      "6    2.734142  -2.934920\n",
      "7   -2.235367 -35.882528\n",
      "8   -9.247184 -11.294760\n",
      "9   -2.506874   3.414932\n",
      "10 -10.875596  -6.151301\n",
      "11   8.516301  14.124754\n",
      "12  12.644743  -8.371513\n",
      "13 -23.568801 -13.020005\n",
      "14  -6.193915 -13.204472\n",
      "15   1.175862   2.668260\n",
      "16  -1.049171   7.912414\n",
      "17 -33.244829 -12.535806\n",
      "18 -18.764721  -7.270688\n",
      "19 -17.301969  -3.496509\n",
      "20  19.195231  11.490442\n",
      "21 -16.634773  -7.502311\n",
      "22  20.725388   8.219658\n",
      "23 -42.550330   4.674671\n",
      "24 -17.711231 -11.622556\n",
      "25  -2.557301  -2.003917\n",
      "26 -80.713612 -11.201560\n",
      "27  19.904204  -5.167999\n",
      "The average error for the 0-axis was:  10.17\n",
      "The average error for the 1-axis was:  4.9\n",
      "Model: \"sequential_632\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1896 (Dense)          (None, 34)                510       \n",
      "                                                                 \n",
      " dense_1897 (Dense)          (None, 34)                1190      \n",
      "                                                                 \n",
      " dense_1898 (Dense)          (None, 2)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,770\n",
      "Trainable params: 1,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 155.5435\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.8611\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.3242\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.2126\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.5937\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6858\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7845\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.0045\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 10.0262\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.2761\n",
      "Model: \"sequential_632\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1896 (Dense)          (None, 34)                510       \n",
      "                                                                 \n",
      " dense_1897 (Dense)          (None, 34)                1190      \n",
      "                                                                 \n",
      " dense_1898 (Dense)          (None, 2)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,770\n",
      "Trainable params: 1,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -0.043180 -12.715652\n",
      "1  -31.534126 -28.763971\n",
      "2  -17.942233 -18.878188\n",
      "3   -2.103107 -13.997914\n",
      "4    6.263502  -6.645653\n",
      "5   -6.060104  -7.817633\n",
      "6    0.171520 -24.438002\n",
      "7   -1.367096 -28.916006\n",
      "8   -7.884482  -4.678549\n",
      "9  -16.630256  -8.920335\n",
      "10 -27.280198  -3.154231\n",
      "11 -15.367244   3.731794\n",
      "12   6.877135 -25.353096\n",
      "13 -10.459716 -12.406602\n",
      "14  -2.208533  -0.742741\n",
      "15  -7.988292   0.803330\n",
      "16  -7.924477   7.412170\n",
      "17 -26.984591  -9.404626\n",
      "18 -14.244488 -18.989911\n",
      "19  -8.388699  -7.975436\n",
      "20  -0.553244   8.189722\n",
      "21 -12.497536  -5.854133\n",
      "22  20.886139  12.489494\n",
      "23 -15.817237 -21.853985\n",
      "24 -10.367725 -36.140180\n",
      "25 -38.999821  16.746770\n",
      "26 -81.200947 -12.344276\n",
      "27   6.734038  -8.662232\n",
      "The average error for the 0-axis was:  11.53\n",
      "The average error for the 1-axis was:  9.62\n",
      "Model: \"sequential_633\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1899 (Dense)          (None, 36)                540       \n",
      "                                                                 \n",
      " dense_1900 (Dense)          (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_1901 (Dense)          (None, 2)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,946\n",
      "Trainable params: 1,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 131.6308\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 27.6384\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 17.8866\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.9312\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.1236\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7552\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.6337\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3952\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9814\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9342\n",
      "Model: \"sequential_633\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1899 (Dense)          (None, 36)                540       \n",
      "                                                                 \n",
      " dense_1900 (Dense)          (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_1901 (Dense)          (None, 2)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,946\n",
      "Trainable params: 1,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0    3.203769   1.042191\n",
      "1   -5.843910  -6.439539\n",
      "2  -20.440737  -7.358046\n",
      "3    4.196088  -2.780461\n",
      "4    6.368849  10.836578\n",
      "5   -2.195113   5.451395\n",
      "6   13.163219  -0.993819\n",
      "7    7.542709 -14.770910\n",
      "8   -1.796897   4.849817\n",
      "9   -9.701851  12.980972\n",
      "10 -25.687455   2.693029\n",
      "11  -4.751247  11.367033\n",
      "12  18.100340 -10.114174\n",
      "13   6.495652  -4.190827\n",
      "14   0.580285   4.264980\n",
      "15  -5.563472   0.839402\n",
      "16  -2.419258  31.812744\n",
      "17 -33.483156   2.125037\n",
      "18  -5.274822   2.036838\n",
      "19   0.058230  10.658231\n",
      "20   3.285166  14.859308\n",
      "21  -7.026009  13.648858\n",
      "22  23.144318  20.390282\n",
      "23  -7.364387  -3.681530\n",
      "24  26.950604 -16.877133\n",
      "25 -45.785039  16.970860\n",
      "26 -57.248402 -10.167686\n",
      "27  18.026290   0.682342\n",
      "The average error for the 0-axis was:  3.7\n",
      "The average error for the 1-axis was:  3.22\n",
      "Model: \"sequential_634\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1902 (Dense)          (None, 38)                570       \n",
      "                                                                 \n",
      " dense_1903 (Dense)          (None, 38)                1482      \n",
      "                                                                 \n",
      " dense_1904 (Dense)          (None, 2)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,130\n",
      "Trainable params: 2,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 77.2691\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.5465\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.8819\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.5981\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.6273\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.1734\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.4180\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0450\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.4073\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.7491\n",
      "Model: \"sequential_634\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1902 (Dense)          (None, 38)                570       \n",
      "                                                                 \n",
      " dense_1903 (Dense)          (None, 38)                1482      \n",
      "                                                                 \n",
      " dense_1904 (Dense)          (None, 2)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,130\n",
      "Trainable params: 2,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -8.446073  -3.647995\n",
      "1   -3.495521 -36.483317\n",
      "2   -8.143374  -9.451033\n",
      "3   -8.782153 -11.246495\n",
      "4   -7.044893  12.773438\n",
      "5   -0.508376  -0.449881\n",
      "6   18.534313  -8.973418\n",
      "7    3.056793  -8.370092\n",
      "8   -1.818717  -7.289068\n",
      "9   -6.904579   7.037902\n",
      "10 -16.477372  -5.365016\n",
      "11  -5.175380  -4.541414\n",
      "12  16.751646 -15.967735\n",
      "13  -5.094222   3.333556\n",
      "14  11.663720  -3.595905\n",
      "15 -11.800777   9.473634\n",
      "16   1.639152  20.441528\n",
      "17 -21.077517   0.856315\n",
      "18 -12.424480 -18.996228\n",
      "19  -6.050626  -6.824115\n",
      "20  -5.537435   9.013086\n",
      "21 -10.602120   2.601586\n",
      "22  18.278443  -6.196571\n",
      "23 -18.301612   2.993122\n",
      "24  12.192029  -1.222257\n",
      "25 -35.718343   5.634358\n",
      "26 -55.517079  13.716912\n",
      "27  11.817824 -21.336701\n",
      "The average error for the 0-axis was:  5.54\n",
      "The average error for the 1-axis was:  2.93\n",
      "Model: \"sequential_635\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1905 (Dense)          (None, 40)                600       \n",
      "                                                                 \n",
      " dense_1906 (Dense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_1907 (Dense)          (None, 2)                 82        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 56.8925\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 25.1277\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 17.0295\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.2231\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.1654\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.6810\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.4554\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.2940\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.7585\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.0524\n",
      "Model: \"sequential_635\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1905 (Dense)          (None, 40)                600       \n",
      "                                                                 \n",
      " dense_1906 (Dense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_1907 (Dense)          (None, 2)                 82        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -0.215421  -2.341141\n",
      "1    7.888268   2.848364\n",
      "2   -7.893099  -3.591841\n",
      "3   -2.852557 -17.064229\n",
      "4    6.973860  17.417961\n",
      "5    5.897904   3.027857\n",
      "6   21.002971   5.359636\n",
      "7    5.616562 -23.264089\n",
      "8    1.824868  -8.192831\n",
      "9   13.269676  20.607940\n",
      "10   1.002883  -1.843623\n",
      "11  28.476415  31.941343\n",
      "12  29.534819  -1.955238\n",
      "13  -6.037124  -7.104661\n",
      "14   8.632776   9.065075\n",
      "15   6.813725   1.707063\n",
      "16  12.611717  18.084534\n",
      "17 -19.948336  -5.181039\n",
      "18   1.219593   2.296695\n",
      "19   2.633365   4.194089\n",
      "20  18.966288  40.100367\n",
      "21   6.459221   5.207253\n",
      "22  34.769272   8.747032\n",
      "23 -15.159858  22.073078\n",
      "24  19.397381  16.130038\n",
      "25 -11.817769  10.369527\n",
      "26 -64.219746  -9.302253\n",
      "27  28.784102  -4.208984\n",
      "The average error for the 0-axis was:  4.77\n",
      "The average error for the 1-axis was:  4.83\n",
      "Model: \"sequential_636\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1908 (Dense)          (None, 42)                630       \n",
      "                                                                 \n",
      " dense_1909 (Dense)          (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_1910 (Dense)          (None, 2)                 86        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,522\n",
      "Trainable params: 2,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 188.5421\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 35.6406\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.3050\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.7119\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.8631\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.1039\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.6381\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.7395\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.0205\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.7276\n",
      "Model: \"sequential_636\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1908 (Dense)          (None, 42)                630       \n",
      "                                                                 \n",
      " dense_1909 (Dense)          (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_1910 (Dense)          (None, 2)                 86        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,522\n",
      "Trainable params: 2,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -5.218991  -9.703308\n",
      "1  -11.917182 -22.509470\n",
      "2  -17.423556  -9.721907\n",
      "3   -6.198306 -10.097584\n",
      "4   12.290068   0.810082\n",
      "5   -9.027236  -0.019446\n",
      "6   21.437114 -15.487853\n",
      "7  -13.461105 -30.534170\n",
      "8   -3.081016  -0.884192\n",
      "9    4.262871   6.611739\n",
      "10 -10.904252   0.862645\n",
      "11  20.192174   6.140501\n",
      "12  18.079680 -16.897300\n",
      "13  -9.764175  -9.592332\n",
      "14   9.345056  -1.464939\n",
      "15   3.163792  -5.653167\n",
      "16  -5.146065  21.380798\n",
      "17 -25.314867   1.262183\n",
      "18   4.117268 -19.186642\n",
      "19   3.566012  -9.155063\n",
      "20  24.433359   7.209177\n",
      "21 -16.074501   5.399041\n",
      "22  30.154785  12.301399\n",
      "23 -24.145026  -7.466381\n",
      "24   3.457867 -12.670865\n",
      "25 -24.075215   8.427571\n",
      "26 -59.162068 -15.554115\n",
      "27  25.314360 -17.401352\n",
      "The average error for the 0-axis was:  2.18\n",
      "The average error for the 1-axis was:  5.13\n",
      "Model: \"sequential_637\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1911 (Dense)          (None, 44)                660       \n",
      "                                                                 \n",
      " dense_1912 (Dense)          (None, 44)                1980      \n",
      "                                                                 \n",
      " dense_1913 (Dense)          (None, 2)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,730\n",
      "Trainable params: 2,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 60.5985\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 21.6872\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.8239\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.1216\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.0367\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.7069\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.8506\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6678\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.8907\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8908\n",
      "Model: \"sequential_637\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1911 (Dense)          (None, 44)                660       \n",
      "                                                                 \n",
      " dense_1912 (Dense)          (None, 44)                1980      \n",
      "                                                                 \n",
      " dense_1913 (Dense)          (None, 2)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,730\n",
      "Trainable params: 2,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   12.671496  -2.414169\n",
      "1   -2.545875  -6.436289\n",
      "2   -5.121951   2.292253\n",
      "3   11.277478  -5.125020\n",
      "4    9.841688  10.444275\n",
      "5    4.765488   7.859094\n",
      "6   18.084087   7.705919\n",
      "7    9.569061 -20.052892\n",
      "8    3.596658   2.645380\n",
      "9   -3.724037  17.007110\n",
      "10 -11.869126  13.671209\n",
      "11  -0.751430  21.779218\n",
      "12  14.231779  -8.189552\n",
      "13  -0.367797   0.841506\n",
      "14  -1.268714  17.978741\n",
      "15  -1.767574  13.862031\n",
      "16   6.448723  30.549499\n",
      "17 -14.927172   4.165473\n",
      "18  -8.419628  -0.256283\n",
      "19  -0.246793   7.125394\n",
      "20   0.063273  16.948130\n",
      "21  -3.323189   6.723320\n",
      "22  36.876801  14.964729\n",
      "23 -17.358833  12.462299\n",
      "24  -1.047779   9.409427\n",
      "25 -19.337331  21.055257\n",
      "26 -62.888050   6.898705\n",
      "27  22.085723  -3.190979\n",
      "The average error for the 0-axis was:  0.19\n",
      "The average error for the 1-axis was:  7.17\n",
      "Model: \"sequential_638\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1914 (Dense)          (None, 46)                690       \n",
      "                                                                 \n",
      " dense_1915 (Dense)          (None, 46)                2162      \n",
      "                                                                 \n",
      " dense_1916 (Dense)          (None, 2)                 94        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,946\n",
      "Trainable params: 2,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 74.4818\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 32.8195\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 23.5604\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 19.1205\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.8775\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.1471\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.1389\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3128\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6974\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6875\n",
      "Model: \"sequential_638\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1914 (Dense)          (None, 46)                690       \n",
      "                                                                 \n",
      " dense_1915 (Dense)          (None, 46)                2162      \n",
      "                                                                 \n",
      " dense_1916 (Dense)          (None, 2)                 94        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,946\n",
      "Trainable params: 2,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0    6.759112  -8.617203\n",
      "1  -14.663459 -17.134287\n",
      "2   -5.023043  -0.890273\n",
      "3   -0.174548 -17.741261\n",
      "4   15.456877   5.539848\n",
      "5   -1.605727   2.529642\n",
      "6   16.395000   7.930437\n",
      "7    1.073578 -24.212804\n",
      "8    0.214272  -5.168814\n",
      "9    2.680229  17.390273\n",
      "10  -3.983323   4.386327\n",
      "11   5.393224  27.800855\n",
      "12  21.390623 -14.535118\n",
      "13  -6.303466  -5.831559\n",
      "14   2.485742   4.214809\n",
      "15   4.621022   8.062867\n",
      "16  11.585106  22.477936\n",
      "17  -9.645708  -3.987756\n",
      "18  -9.354534 -17.517209\n",
      "19  -4.453793  -9.969165\n",
      "20   4.204966  32.774210\n",
      "21  -7.809242  -4.882316\n",
      "22  31.184281   0.277748\n",
      "23  -6.186652   1.043842\n",
      "24  10.289532  -0.772153\n",
      "25 -16.025822  18.684041\n",
      "26 -68.168476   6.555718\n",
      "27  24.201415 -17.125946\n",
      "The average error for the 0-axis was:  0.16\n",
      "The average error for the 1-axis was:  0.4\n",
      "Model: \"sequential_639\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1917 (Dense)          (None, 48)                720       \n",
      "                                                                 \n",
      " dense_1918 (Dense)          (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_1919 (Dense)          (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,170\n",
      "Trainable params: 3,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 84.4916\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 25.6617\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.5316\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.9939\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.0477\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8544\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.9954\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 12.7096\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 13.0380\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 12.6857\n",
      "Model: \"sequential_639\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1917 (Dense)          (None, 48)                720       \n",
      "                                                                 \n",
      " dense_1918 (Dense)          (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_1919 (Dense)          (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,170\n",
      "Trainable params: 3,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -2.522443 -31.775848\n",
      "1  -16.054542 -10.589304\n",
      "2  -12.242526 -18.650038\n",
      "3   -0.991351 -21.342518\n",
      "4   -2.691271  -1.041237\n",
      "5    7.185044 -11.038672\n",
      "6    7.755138  -8.666960\n",
      "7  -11.435211 -31.870229\n",
      "8    5.659371 -13.436712\n",
      "9    2.774468   5.138641\n",
      "10 -16.936570  -4.824732\n",
      "11  16.587407   0.270582\n",
      "12  19.680113  -5.515053\n",
      "13 -17.261443 -18.745560\n",
      "14   0.991815  -2.267979\n",
      "15 -20.220333   7.718263\n",
      "16   0.051414   5.097778\n",
      "17 -30.033251 -16.761941\n",
      "18  -7.248608 -10.412716\n",
      "19  -2.142301  -7.302066\n",
      "20   5.542399  -9.661398\n",
      "21  -1.696144  -0.142585\n",
      "22  35.804581 -12.573769\n",
      "23 -35.167365  -5.864391\n",
      "24 -13.791187  -2.772763\n",
      "25 -29.583943   2.166478\n",
      "26 -74.194447   8.533379\n",
      "27   4.109923  -7.687378\n",
      "The average error for the 0-axis was:  6.72\n",
      "The average error for the 1-axis was:  8.0\n",
      "Model: \"sequential_640\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1920 (Dense)          (None, 50)                750       \n",
      "                                                                 \n",
      " dense_1921 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1922 (Dense)          (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 4ms/step - loss: 153.8883\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 34.1115\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 22.5724\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 17.6621\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.3379\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 12.3915\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 11.3251\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10.4787\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.7218\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.4809\n",
      "Model: \"sequential_640\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1920 (Dense)          (None, 50)                750       \n",
      "                                                                 \n",
      " dense_1921 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1922 (Dense)          (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -6.748242   6.605393\n",
      "1  -13.745643   1.252935\n",
      "2  -19.350619   8.538560\n",
      "3  -10.057330   7.379604\n",
      "4    5.619688   0.308716\n",
      "5   -3.431625  19.431375\n",
      "6    3.500743  16.770494\n",
      "7  -13.765930  -1.375127\n",
      "8   -8.696250   8.970041\n",
      "9  -10.716743  13.129134\n",
      "10 -22.926499  24.182836\n",
      "11   1.568700  18.900129\n",
      "12   2.345701   2.928032\n",
      "13 -19.605956  -2.634202\n",
      "14 -11.762488  11.895824\n",
      "15  -5.943187  21.603532\n",
      "16 -13.724312  39.907837\n",
      "17 -32.989275   9.572990\n",
      "18 -24.843853  -2.648861\n",
      "19 -20.263059   8.726529\n",
      "20   3.628672  37.257532\n",
      "21 -14.007210   7.295983\n",
      "22  30.079666  29.195000\n",
      "23 -25.296882  14.110554\n",
      "24  -0.084369  -5.994168\n",
      "25 -17.076695  38.732747\n",
      "26 -88.990376  10.024987\n",
      "27   6.889708  17.681152\n",
      "The average error for the 0-axis was:  11.8\n",
      "The average error for the 1-axis was:  12.92\n",
      "Model: \"sequential_641\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1923 (Dense)          (None, 52)                780       \n",
      "                                                                 \n",
      " dense_1924 (Dense)          (None, 52)                2756      \n",
      "                                                                 \n",
      " dense_1925 (Dense)          (None, 2)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 177.2749\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 38.8569\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 19.8000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.2293\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.1007\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.7859\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 10.1718\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.3395\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4394\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.1082\n",
      "Model: \"sequential_641\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1923 (Dense)          (None, 52)                780       \n",
      "                                                                 \n",
      " dense_1924 (Dense)          (None, 52)                2756      \n",
      "                                                                 \n",
      " dense_1925 (Dense)          (None, 2)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0  -15.670285  -8.468689\n",
      "1   -1.018836  -9.782068\n",
      "2  -13.397189  -9.421752\n",
      "3   -7.306781  -7.795521\n",
      "4    0.451002   1.257187\n",
      "5   -2.436507   4.483438\n",
      "6   18.728496  -5.481429\n",
      "7   -6.015228 -18.772909\n",
      "8   -6.339957  -2.134085\n",
      "9   -7.617775   6.509933\n",
      "10 -19.092790   7.056920\n",
      "11   6.584294   4.207197\n",
      "12  22.968565  -8.882896\n",
      "13 -18.496139  -6.083497\n",
      "14   6.538598   4.823833\n",
      "15  -2.039165  11.756501\n",
      "16  -2.166359  22.041107\n",
      "17 -26.324892   0.822196\n",
      "18  -7.035381 -11.440213\n",
      "19  -6.303128  -2.254626\n",
      "20   7.022867  -2.955099\n",
      "21 -10.334511  -0.097831\n",
      "22  17.242264   4.783928\n",
      "23 -23.965186   8.145283\n",
      "24   5.444470   6.529544\n",
      "25 -30.275838  11.900349\n",
      "26 -57.748371   5.532738\n",
      "27  13.959365  -3.829010\n",
      "The average error for the 0-axis was:  5.88\n",
      "The average error for the 1-axis was:  0.09\n",
      "Model: \"sequential_642\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1926 (Dense)          (None, 54)                810       \n",
      "                                                                 \n",
      " dense_1927 (Dense)          (None, 54)                2970      \n",
      "                                                                 \n",
      " dense_1928 (Dense)          (None, 2)                 110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,890\n",
      "Trainable params: 3,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 122.5562\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 27.4990\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 15.6112\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.1387\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.3168\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.1793\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 14.7616\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5126\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.3654\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.5261\n",
      "Model: \"sequential_642\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1926 (Dense)          (None, 54)                810       \n",
      "                                                                 \n",
      " dense_1927 (Dense)          (None, 54)                2970      \n",
      "                                                                 \n",
      " dense_1928 (Dense)          (None, 2)                 110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,890\n",
      "Trainable params: 3,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0   -5.886792   1.513809\n",
      "1  -21.688026  -7.095499\n",
      "2  -16.338992   0.191453\n",
      "3   -7.642963  -4.946126\n",
      "4    8.244825  -2.680431\n",
      "5   -5.317489   7.020166\n",
      "6   11.302989   2.155809\n",
      "7   -0.894455  -7.374486\n",
      "8   -7.086600  -1.433020\n",
      "9  -15.493171  16.479339\n",
      "10 -19.648606   8.277044\n",
      "11  -7.958461  10.354933\n",
      "12   8.820616  -7.237831\n",
      "13 -14.322295   3.046706\n",
      "14  -6.369117   8.265377\n",
      "15  -0.219936  17.132050\n",
      "16  -4.348030  24.430847\n",
      "17 -25.798433   5.045844\n",
      "18 -13.172405 -10.946713\n",
      "19  -6.232602  -4.227466\n",
      "20  10.149973   9.344522\n",
      "21 -15.751656  12.391777\n",
      "22  20.818909   8.248192\n",
      "23 -22.419379  11.229877\n",
      "24  -2.641529   4.511935\n",
      "25 -27.904713  34.862370\n",
      "26 -75.030690  10.055535\n",
      "27  15.101104   0.909790\n",
      "The average error for the 0-axis was:  8.85\n",
      "The average error for the 1-axis was:  5.34\n",
      "Model: \"sequential_643\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1929 (Dense)          (None, 56)                840       \n",
      "                                                                 \n",
      " dense_1930 (Dense)          (None, 56)                3192      \n",
      "                                                                 \n",
      " dense_1931 (Dense)          (None, 2)                 114       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,146\n",
      "Trainable params: 4,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 108.7263\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 26.2558\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 15.5229\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 13.0402\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.3589\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 13.5228\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.3900\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.7728\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 10.0038\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 11.3895\n",
      "Model: \"sequential_643\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1929 (Dense)          (None, 56)                840       \n",
      "                                                                 \n",
      " dense_1930 (Dense)          (None, 56)                3192      \n",
      "                                                                 \n",
      " dense_1931 (Dense)          (None, 2)                 114       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,146\n",
      "Trainable params: 4,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Printing\n",
      "            0          1\n",
      "0  -26.669339 -29.338028\n",
      "1  -38.260871 -29.995753\n",
      "2  -18.093325 -24.353560\n",
      "3  -26.084689 -21.902669\n",
      "4   -3.767595   6.152870\n",
      "5  -12.208175 -12.346716\n",
      "6   -4.110341 -21.412062\n",
      "7  -17.003647 -43.982366\n",
      "8  -14.217033 -16.717322\n",
      "9   -6.250190  -4.077302\n",
      "10 -12.690354 -13.175440\n",
      "11   4.506932  -3.042757\n",
      "12   6.749449 -29.342094\n",
      "13 -28.249191 -24.935487\n",
      "14  -9.144660 -11.834690\n",
      "15   2.877232  -2.641891\n",
      "16   4.475944  -2.574310\n",
      "17 -18.407106  -6.648873\n",
      "18 -29.995678 -31.862439\n",
      "19 -26.118222 -23.472934\n",
      "20  20.522837   7.461328\n",
      "21 -18.446785  -6.944404\n",
      "22   9.868683  -9.456001\n",
      "23 -43.601630 -12.700939\n",
      "24 -15.423328 -11.331723\n",
      "25   2.229961   6.016225\n",
      "26 -80.031544 -15.824180\n",
      "27   2.325499 -20.052872\n",
      "The average error for the 0-axis was:  14.11\n",
      "The average error for the 1-axis was:  14.65\n",
      "Model: \"sequential_644\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1932 (Dense)          (None, 58)                870       \n",
      "                                                                 \n",
      " dense_1933 (Dense)          (None, 58)                3422      \n",
      "                                                                 \n",
      " dense_1934 (Dense)          (None, 2)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,410\n",
      "Trainable params: 4,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24008\\235037123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_error\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_2d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_2d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_2d_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_2d_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0merrores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mavg_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24008\\1726945996.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(df_in, df_out, df_in_test, df_out_test, neurons, output, epoch)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_in_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_out_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mneurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24008\\856977105.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(df_in, df_out, neurons, output, epoch)\u001b[0m\n\u001b[0;32m     25\u001b[0m                         \u001b[0mdf_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatchs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     )\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1680\u001b[0m                         ):\n\u001b[0;32m   1681\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1682\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1683\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    926\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 928\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m    \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         ._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m--> 751\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;34m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m       \u001b[0mconcrete_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m           \u001b[0mconcrete_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m           \u001b[0mgraph_capture_container\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_capture_func_lib\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[0mautograph_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mspec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1264\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m                     \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m                 ))\n\u001b[0;32m   1268\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1263\u001b[0m                 )\n\u001b[0;32m   1264\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m             outputs = reduce_per_replica(\n\u001b[0;32m   1267\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1316\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2894\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2897\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3694\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3695\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3696\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m                 \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    525\u001b[0m         \"\"\"\n\u001b[0;32m    526\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compute_current_learning_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m             \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m         )\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[1;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m   \"\"\"\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[1;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             distribution.extended.update(\n\u001b[1;32m-> 1217\u001b[1;33m                 \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m             )\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2639\u001b[0m       return self._replica_ctx_update(\n\u001b[1;32m-> 2640\u001b[1;33m           var, fn, args=args, kwargs=kwargs, group=group)\n\u001b[0m\u001b[0;32m   2641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_replica_ctx_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2518\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2520\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_gather_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3108\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[0;32m   3109\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 3110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3112\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3115\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[0;32m   3116\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3117\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3118\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3119\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mmerge_fn\u001b[1;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmerged_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmerged_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2516\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerged_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreplica_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2635\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m   2636\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2637\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2639\u001b[0m       return self._replica_ctx_update(\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3708\u001b[0m     \u001b[1;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3709\u001b[0m     \u001b[1;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3710\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3712\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   3714\u001b[0m     \u001b[1;31m# once that value is used for something.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3715\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3716\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3717\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3718\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_update_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;34m\"`tf.keras.optimizers.legacy.{self.__class__.__name__}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             )\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mv_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign_sub\u001b[1;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    866\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m           \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m           name=name)\n\u001b[0m\u001b[0;32m    869\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_sub_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_sub_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m--> 107\u001b[1;33m         \"AssignSubVariableOp\", resource=resource, value=value, name=name)\n\u001b[0m\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[0mAssignSubVariableOp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raw_ops.AssignSubVariableOp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_sub_variable_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    795\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    796\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    750\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3804\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3805\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3806\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3807\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m     \u001b[1;31m# Initialize c_op from node_def and other inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2106\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_c_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_input_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2107\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_c_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ferro\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1937\u001b[0m     op_desc = pywrap_tf_session.TF_NewOperation(c_graph,\n\u001b[0;32m   1938\u001b[0m                                                 \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1939\u001b[1;33m                                                 compat.as_str(node_def.name))\n\u001b[0m\u001b[0;32m   1940\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1941\u001b[0m     \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = 2\n",
    "\n",
    "neurons = 32\n",
    "epoch = 10\n",
    "\n",
    "threshold = 0.1\n",
    "err = threshold + 1.0\n",
    "errores = [err, err]\n",
    "\n",
    "while(avg_error > threshold):\n",
    "    results = run(in_2d_train, out_2d_train, in_2d_test, out_2d_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    avg_error = np.mean(np.array(errores))\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    "\n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the second model will be ran and its name will be \"THE AXIS INDEPENDENT MODEL\". This model is caracterized by taking the 7 attributes as input, and giving one output as one of the coordinates of the location of the mouse. Therefore, this model will be run two times per simulation, one for x-axis and another one for the y-axis. The point of using as input the x-axis data and the y-axis separately, that is to say, in separate models, is to check the influence of x-axis values on y-axis result and viceversa.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for the coordinates in x-axis we run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_625\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1875 (Dense)          (None, 16)                128       \n",
      "                                                                 \n",
      " dense_1876 (Dense)          (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1877 (Dense)          (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 200.9052\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 47.4413\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.5283\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 17.3613\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.3380\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.8276\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.4296\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.5766\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.1145\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.7622\n",
      "Model: \"sequential_625\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1875 (Dense)          (None, 16)                128       \n",
      "                                                                 \n",
      " dense_1876 (Dense)          (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1877 (Dense)          (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417\n",
      "Trainable params: 417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Printing\n",
      "            0\n",
      "0  -11.784707\n",
      "1   10.756427\n",
      "2  -65.318129\n",
      "3   -2.167742\n",
      "4   -9.105432\n",
      "5    3.453871\n",
      "6   -9.734260\n",
      "7   -1.195900\n",
      "8  -10.801501\n",
      "9  -11.717667\n",
      "10  -9.043818\n",
      "11  13.155383\n",
      "12 -20.307932\n",
      "13 -10.420804\n",
      "14  -7.919226\n",
      "15 -14.053916\n",
      "16   6.696118\n",
      "17  10.218272\n",
      "18  -3.249731\n",
      "19 -12.462891\n",
      "20  -6.766437\n",
      "21  -7.522391\n",
      "22  -4.426163\n",
      "23   4.519440\n",
      "24  -8.675881\n",
      "25  -4.143397\n",
      "26 -17.999322\n",
      "27  -8.635784\n",
      "The average error for the 0-axis was:  7.45\n",
      "Model: \"sequential_626\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1878 (Dense)          (None, 18)                144       \n",
      "                                                                 \n",
      " dense_1879 (Dense)          (None, 18)                342       \n",
      "                                                                 \n",
      " dense_1880 (Dense)          (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505\n",
      "Trainable params: 505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 438.9219\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 250.5703\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 65.1015\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.8198\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.0021\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.1911\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5961\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9264\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.3751\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9202\n",
      "Model: \"sequential_626\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1878 (Dense)          (None, 18)                144       \n",
      "                                                                 \n",
      " dense_1879 (Dense)          (None, 18)                342       \n",
      "                                                                 \n",
      " dense_1880 (Dense)          (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505\n",
      "Trainable params: 505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Printing\n",
      "            0\n",
      "0   -4.645425\n",
      "1   -3.162961\n",
      "2  -35.266646\n",
      "3  -15.304980\n",
      "4   -7.136224\n",
      "5    2.037947\n",
      "6    5.943078\n",
      "7    0.766670\n",
      "8    3.933607\n",
      "9    9.798080\n",
      "10   2.922978\n",
      "11   2.171679\n",
      "12   2.334982\n",
      "13   1.094210\n",
      "14   3.046319\n",
      "15  20.752756\n",
      "16   8.401837\n",
      "17  13.634105\n",
      "18  18.749841\n",
      "19  -2.361267\n",
      "20  -0.633121\n",
      "21   8.685449\n",
      "22  -5.040253\n",
      "23   9.468597\n",
      "24  11.612113\n",
      "25  27.732518\n",
      "26   5.454200\n",
      "27   5.192341\n",
      "The average error for the 0-axis was:  3.22\n",
      "Model: \"sequential_627\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1881 (Dense)          (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1882 (Dense)          (None, 20)                420       \n",
      "                                                                 \n",
      " dense_1883 (Dense)          (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 71.4222\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 26.1217\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 21.1241\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.8011\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.2328\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.7055\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.1176\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9821\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.5921\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.6951\n",
      "Model: \"sequential_627\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1881 (Dense)          (None, 20)                160       \n",
      "                                                                 \n",
      " dense_1882 (Dense)          (None, 20)                420       \n",
      "                                                                 \n",
      " dense_1883 (Dense)          (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Printing\n",
      "            0\n",
      "0   -1.602334\n",
      "1    5.644443\n",
      "2  -21.764571\n",
      "3  -10.742541\n",
      "4   -4.205072\n",
      "5   11.451200\n",
      "6    6.282739\n",
      "7    1.131141\n",
      "8    3.668470\n",
      "9   10.897079\n",
      "10  14.793065\n",
      "11   1.602130\n",
      "12   6.267141\n",
      "13  11.945834\n",
      "14  13.404687\n",
      "15   5.415170\n",
      "16  24.915082\n",
      "17  25.681956\n",
      "18  21.528040\n",
      "19   5.107086\n",
      "20  -1.201053\n",
      "21   6.018762\n",
      "22   2.139450\n",
      "23  15.116608\n",
      "24  12.141593\n",
      "25  30.709325\n",
      "26  15.995033\n",
      "27   4.412617\n",
      "The average error for the 0-axis was:  7.74\n",
      "Model: \"sequential_628\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1884 (Dense)          (None, 22)                176       \n",
      "                                                                 \n",
      " dense_1885 (Dense)          (None, 22)                506       \n",
      "                                                                 \n",
      " dense_1886 (Dense)          (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 308.6191\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 67.5080\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.9929\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.1033\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.3517\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0850\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9661\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3860\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3565\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.5732\n",
      "Model: \"sequential_628\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1884 (Dense)          (None, 22)                176       \n",
      "                                                                 \n",
      " dense_1885 (Dense)          (None, 22)                506       \n",
      "                                                                 \n",
      " dense_1886 (Dense)          (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Printing\n",
      "            0\n",
      "0   -9.003656\n",
      "1  -10.877499\n",
      "2  -27.151503\n",
      "3  -13.336108\n",
      "4  -18.905542\n",
      "5   -2.738451\n",
      "6   -0.070808\n",
      "7    0.920417\n",
      "8   -2.668505\n",
      "9    2.652908\n",
      "10   0.634496\n",
      "11   2.261935\n",
      "12  -5.616678\n",
      "13  -6.977262\n",
      "14  -2.461554\n",
      "15  12.526590\n",
      "16  -1.857745\n",
      "17  10.521312\n",
      "18  16.145777\n",
      "19  -6.970337\n",
      "20  -8.824390\n",
      "21   7.485467\n",
      "22  -9.841431\n",
      "23   7.220428\n",
      "24   3.609550\n",
      "25  21.003026\n",
      "26  -1.408166\n",
      "27  -1.637066\n",
      "The average error for the 0-axis was:  1.62\n",
      "Model: \"sequential_629\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1887 (Dense)          (None, 24)                192       \n",
      "                                                                 \n",
      " dense_1888 (Dense)          (None, 24)                600       \n",
      "                                                                 \n",
      " dense_1889 (Dense)          (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 817\n",
      "Trainable params: 817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 354.4664\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 158.5925\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.1213\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 20.3359\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.8402\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 16.0403\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.8741\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.1045\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 13.0524\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.3472\n",
      "Model: \"sequential_629\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1887 (Dense)          (None, 24)                192       \n",
      "                                                                 \n",
      " dense_1888 (Dense)          (None, 24)                600       \n",
      "                                                                 \n",
      " dense_1889 (Dense)          (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 817\n",
      "Trainable params: 817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Printing\n",
      "            0\n",
      "0   -0.132791\n",
      "1    7.382831\n",
      "2  -34.527205\n",
      "3  -11.662157\n",
      "4   -2.099756\n",
      "5   11.177793\n",
      "6    5.910149\n",
      "7    5.755043\n",
      "8    0.437330\n",
      "9    8.037308\n",
      "10  18.152867\n",
      "11  19.362720\n",
      "12  -9.496195\n",
      "13  13.376681\n",
      "14   9.230645\n",
      "15  11.424722\n",
      "16  19.463452\n",
      "17  13.511455\n",
      "18   7.001428\n",
      "19   6.169037\n",
      "20   1.909528\n",
      "21   4.698068\n",
      "22  -0.254151\n",
      "23   9.303741\n",
      "24   5.638786\n",
      "25   9.245977\n",
      "26  -0.939660\n",
      "27   2.351307\n",
      "The average error for the 0-axis was:  4.66\n",
      "Model: \"sequential_630\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1890 (Dense)          (None, 26)                208       \n",
      "                                                                 \n",
      " dense_1891 (Dense)          (None, 26)                702       \n",
      "                                                                 \n",
      " dense_1892 (Dense)          (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937\n",
      "Trainable params: 937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 75.0833\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 28.2826\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.6167\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.2911\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.0320\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3231\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.6835\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.2700\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.5395\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.1500\n",
      "Model: \"sequential_630\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1890 (Dense)          (None, 26)                208       \n",
      "                                                                 \n",
      " dense_1891 (Dense)          (None, 26)                702       \n",
      "                                                                 \n",
      " dense_1892 (Dense)          (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937\n",
      "Trainable params: 937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Printing\n",
      "            0\n",
      "0  -10.832864\n",
      "1    0.008243\n",
      "2  -40.234450\n",
      "3   -6.089007\n",
      "4  -10.739099\n",
      "5    5.453871\n",
      "6   -5.793494\n",
      "7   -4.658379\n",
      "8   -2.714404\n",
      "9   -4.156601\n",
      "10   7.919469\n",
      "11   8.504230\n",
      "12  -7.282053\n",
      "13   7.914675\n",
      "14   6.824212\n",
      "15   4.332315\n",
      "16  -0.083820\n",
      "17   7.701366\n",
      "18   4.227686\n",
      "19  -0.197205\n",
      "20  -6.221301\n",
      "21   2.348931\n",
      "22  -2.293290\n",
      "23   7.177673\n",
      "24  -3.055184\n",
      "25  31.940831\n",
      "26  -0.285912\n",
      "27  -2.793652\n",
      "The average error for the 0-axis was:  0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model has 28 neurons per hidden layer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neurons = int(neurons / 2)\n",
    "output = 1\n",
    "\n",
    "\n",
    "while(errores[0] > threshold):\n",
    "    results = run(in_x_train, out_x_train, in_x_test, out_x_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    "\n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noww, we run it for the coordinates in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model has 28 neurons per hidden layer\n"
     ]
    }
   ],
   "source": [
    "output = 1\n",
    "\n",
    "while(errores[0] > threshold):\n",
    "    results = run(in_y_train, out_y_train, in_y_test, out_y_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    "\n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fec7c492cb63a891b61f6a129c254b2f9b08ab3c88ef1c1ffe13c4cf2a66800d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
