{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 3 \n",
    "# CS584 MACHINE LEARNING \n",
    "# JULEN FERRO BAÑALES\n",
    "This Jupyter Notebook will include the coding of the Homework 3 related to the subject CS584 Machine Learning, as well as some comments made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, some basic auxiliary functions will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning(df):\n",
    "    df = df.drop(['rightdown'], axis=1, level= 1)\n",
    "    df = df.drop(['topleft'], axis=1, level= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that must be done, is to read the CSV file with the location data that has been obtained after processing the mice images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th colspan=\"18\" halign=\"left\">annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>Unnamed: 1_level_1</th>\n",
       "      <th>Unnamed: 2_level_1</th>\n",
       "      <th colspan=\"7\" halign=\"left\">mouse1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">mouse2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th>Unnamed: 1_level_2</th>\n",
       "      <th>Unnamed: 2_level_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">topleft</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightdown</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th>leftear</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>Unnamed: 1_level_3</th>\n",
       "      <th>Unnamed: 2_level_3</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>12.903231</td>\n",
       "      <td>544.739689</td>\n",
       "      <td>331.769622</td>\n",
       "      <td>517.657886</td>\n",
       "      <td>21.639296</td>\n",
       "      <td>504.553788</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>286.152150</td>\n",
       "      <td>140.449787</td>\n",
       "      <td>516.784280</td>\n",
       "      <td>315.171098</td>\n",
       "      <td>515.910673</td>\n",
       "      <td>175.394049</td>\n",
       "      <td>488.828870</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>238.977396</td>\n",
       "      <td>154.427492</td>\n",
       "      <td>394.479362</td>\n",
       "      <td>225.189623</td>\n",
       "      <td>247.713462</td>\n",
       "      <td>212.085524</td>\n",
       "      <td>267.806412</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>230.241331</td>\n",
       "      <td>166.657984</td>\n",
       "      <td>310.613133</td>\n",
       "      <td>239.167328</td>\n",
       "      <td>287.899363</td>\n",
       "      <td>192.866180</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>233.735757</td>\n",
       "      <td>173.646836</td>\n",
       "      <td>299.256248</td>\n",
       "      <td>261.007491</td>\n",
       "      <td>240.724609</td>\n",
       "      <td>187.624541</td>\n",
       "      <td>251.207888</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         scorer Unnamed: 1_level_0  \\\n",
       "    individuals Unnamed: 1_level_1   \n",
       "      bodyparts Unnamed: 1_level_2   \n",
       "         coords Unnamed: 1_level_3   \n",
       "0  labeled-data               24.0   \n",
       "1  labeled-data               24.0   \n",
       "2  labeled-data               24.0   \n",
       "3  labeled-data               24.0   \n",
       "4  labeled-data               24.0   \n",
       "\n",
       "                                  Unnamed: 2_level_0  annotation              \\\n",
       "                                  Unnamed: 2_level_1      mouse1               \n",
       "                                  Unnamed: 2_level_2     topleft               \n",
       "                                  Unnamed: 2_level_3           x           y   \n",
       "0  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  273.048052   12.903231   \n",
       "1  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  286.152150  140.449787   \n",
       "2  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  238.977396  154.427492   \n",
       "3  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  230.241331  166.657984   \n",
       "4  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  233.735757  173.646836   \n",
       "\n",
       "                                                               ...           \\\n",
       "                                                               ...   mouse2   \n",
       "    rightdown                    nose                 leftear  ... rightear   \n",
       "            x           y           x           y           x  ...        x   \n",
       "0  544.739689  331.769622  517.657886   21.639296  504.553788  ...      NaN   \n",
       "1  516.784280  315.171098  515.910673  175.394049  488.828870  ...      NaN   \n",
       "2  394.479362  225.189623  247.713462  212.085524  267.806412  ...      NaN   \n",
       "3  310.613133  239.167328  287.899363  192.866180  273.048052  ...      NaN   \n",
       "4  299.256248  261.007491  240.724609  187.624541  251.207888  ...      NaN   \n",
       "\n",
       "                                                         \n",
       "                                                         \n",
       "      leftHip     rightHip     tailBase     tailEnd      \n",
       "    y       x   y        x   y        x   y       x   y  \n",
       "0 NaN     NaN NaN      NaN NaN      NaN NaN     NaN NaN  \n",
       "1 NaN     NaN NaN      NaN NaN      NaN NaN     NaN NaN  \n",
       "2 NaN     NaN NaN      NaN NaN      NaN NaN     NaN NaN  \n",
       "3 NaN     NaN NaN      NaN NaN      NaN NaN     NaN NaN  \n",
       "4 NaN     NaN NaN      NaN NaN      NaN NaN     NaN NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# reading the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\", header = [0, 1, 2, 3])\n",
    "df = pd.DataFrame(df) \n",
    "\n",
    "size = os.path.getsize(r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\")\n",
    "\n",
    "# displaying the contents of the CSV file\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, the dataset will be processed in order to get the dataset structure needed to feed the Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = len(df) #getting the number of data examples that we have\n",
    "df = df.iloc[: , 3:-1]\n",
    "mouse1 = df.xs('mouse1', level=1, axis=1).dropna()\n",
    "mouse2 = df.xs('mouse2', level=1, axis=1).dropna()\n",
    "\n",
    "# we add as rows the mouse2 samples' data taken in pictures where more than one mice were found\n",
    "df = pd.concat([mouse1, mouse2], axis=0)\n",
    "\n",
    "# we create one dataset per axis with data related to its own axis\n",
    "df_x = df.xs('x', level=2, axis=1)\n",
    "df_y = df.xs('y', level=2, axis=1)\n",
    "\n",
    "# we calculate the average location of the mice in both axis\n",
    "x_cg = (df_x.xs('topleft', level=1, axis=1) + df_x.xs('rightdown', level=1, axis=1)) / 2\n",
    "y_cg = (df_y.xs('topleft', level=1, axis=1) + df_y.xs('rightdown', level=1, axis=1)) / 2\n",
    "\n",
    "# renaming the columns of the dataframes\n",
    "x_cg.rename(columns = {'annotation':'x_location'}, inplace = True)\n",
    "y_cg.rename(columns = {'annotation':'y_location'}, inplace = True)\n",
    "\n",
    "# we get rid of the data used for calculating the average location of the mice in both axis\n",
    "df = cleaning(df)\n",
    "df_x = cleaning(df_x)\n",
    "df_y = cleaning(df_y)\n",
    "\n",
    "# we add to df the calculated average location of the mice in both axis\n",
    "df = df.assign(x_locatin = x_cg)\n",
    "df = df.assign(y_location = y_cg)\n",
    "\n",
    "#print(df_x)\n",
    "# df_x is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "#print(df_y)\n",
    "# df_y is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "#print(df)\n",
    "# df is a dataset made up of 187 rows and 16 columns ( 7 attributes per axis + one location per axis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, the fed datasets will be divided in training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x_location  y_location\n",
      "0    408.893870  172.336426\n",
      "1    401.468215  227.810442\n",
      "2    316.728379  189.808557\n",
      "3    270.427232  202.912656\n",
      "4    266.496002  217.327164\n",
      "..          ...         ...\n",
      "121  488.392067  196.797410\n",
      "122  262.564773  156.611508\n",
      "123  479.656001  203.349459\n",
      "124  535.566821  271.927573\n",
      "125  548.670919  308.182245\n",
      "\n",
      "[187 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "coef = 0.2\n",
    "\n",
    "# x_cg and y_cg will be the respective results for the testing and training of the 7 atributes fed Neural Network\n",
    "# y_2d will be the respective result for the testing and training of the 14 atributes fed Neural Network\n",
    "y_2d = pd.concat([x_cg, y_cg], axis = 1, )\n",
    "print(y_2d)\n",
    "\n",
    "in_x_train, out_x_train, in_x_test, out_x_test = train_test_split(df_x, x_cg, test_size = coef)\n",
    "in_y_train, out_y_train, in_y_test, out_y_test = train_test_split(df_y, y_cg, test_size = coef)\n",
    "in_2d_train, out_2d_train, in_2d_test, out_2d_test = train_test_split(df, y_2d, test_size = coef)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the Neural Network model will be created by using the Tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21472\\3314208492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model = tf.keras.Sequential([\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_shape = [x_train.shape[1]]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Dense(units=2,input_shape=input_shape)])\n",
    " \n",
    "# printing a summary in order to check if it works\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fec7c492cb63a891b61f6a129c254b2f9b08ab3c88ef1c1ffe13c4cf2a66800d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
