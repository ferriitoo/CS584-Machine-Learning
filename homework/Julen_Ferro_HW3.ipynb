{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 3 \n",
    "# CS584 MACHINE LEARNING \n",
    "# JULEN FERRO BAÃ‘ALES\n",
    "This Jupyter Notebook will include the coding of the Homework 3 related to the subject CS584 Machine Learning, as well as some comments made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plot_keras_history import show_history, plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, some basic auxiliary functions will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaning(df):\n",
    "    df = df.drop(['rightdown'], axis=1, level= 1)\n",
    "    df = df.drop(['topleft'], axis=1, level= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that must be done, is to read the CSV file with the location data that has been obtained after processing the mice images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th colspan=\"36\" halign=\"left\">annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>Unnamed: 1_level_1</th>\n",
       "      <th>Unnamed: 2_level_1</th>\n",
       "      <th colspan=\"18\" halign=\"left\">mouse1</th>\n",
       "      <th colspan=\"18\" halign=\"left\">mouse2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th>Unnamed: 1_level_2</th>\n",
       "      <th>Unnamed: 2_level_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">topleft</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightdown</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "      <th colspan=\"2\" halign=\"left\">topleft</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightdown</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>Unnamed: 1_level_3</th>\n",
       "      <th>Unnamed: 2_level_3</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>12.903231</td>\n",
       "      <td>544.739689</td>\n",
       "      <td>331.769622</td>\n",
       "      <td>517.657886</td>\n",
       "      <td>21.639296</td>\n",
       "      <td>504.553788</td>\n",
       "      <td>51.341919</td>\n",
       "      <td>464.367887</td>\n",
       "      <td>59.204378</td>\n",
       "      <td>532.509198</td>\n",
       "      <td>169.278803</td>\n",
       "      <td>481.840018</td>\n",
       "      <td>168.405197</td>\n",
       "      <td>462.620673</td>\n",
       "      <td>251.397819</td>\n",
       "      <td>307.118707</td>\n",
       "      <td>295.951753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>286.152150</td>\n",
       "      <td>140.449787</td>\n",
       "      <td>516.784280</td>\n",
       "      <td>315.171098</td>\n",
       "      <td>515.910673</td>\n",
       "      <td>175.394049</td>\n",
       "      <td>488.828870</td>\n",
       "      <td>148.312246</td>\n",
       "      <td>457.379034</td>\n",
       "      <td>152.680279</td>\n",
       "      <td>478.345591</td>\n",
       "      <td>234.799295</td>\n",
       "      <td>425.055592</td>\n",
       "      <td>229.557655</td>\n",
       "      <td>412.825100</td>\n",
       "      <td>262.754704</td>\n",
       "      <td>293.141002</td>\n",
       "      <td>285.468475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>238.977396</td>\n",
       "      <td>154.427492</td>\n",
       "      <td>394.479362</td>\n",
       "      <td>225.189623</td>\n",
       "      <td>247.713462</td>\n",
       "      <td>212.085524</td>\n",
       "      <td>267.806412</td>\n",
       "      <td>203.349459</td>\n",
       "      <td>272.174445</td>\n",
       "      <td>198.107820</td>\n",
       "      <td>300.129855</td>\n",
       "      <td>198.107820</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>187.624541</td>\n",
       "      <td>336.821330</td>\n",
       "      <td>189.371754</td>\n",
       "      <td>404.089034</td>\n",
       "      <td>217.327164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>230.241331</td>\n",
       "      <td>166.657984</td>\n",
       "      <td>310.613133</td>\n",
       "      <td>239.167328</td>\n",
       "      <td>287.899363</td>\n",
       "      <td>192.866180</td>\n",
       "      <td>273.048052</td>\n",
       "      <td>184.130115</td>\n",
       "      <td>280.036904</td>\n",
       "      <td>196.360606</td>\n",
       "      <td>253.828707</td>\n",
       "      <td>196.360606</td>\n",
       "      <td>269.553625</td>\n",
       "      <td>210.338311</td>\n",
       "      <td>245.092642</td>\n",
       "      <td>221.695196</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>234.799295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>labeled-data</td>\n",
       "      <td>24.0</td>\n",
       "      <td>A_male_in_a_new_cage_face_view_3_2022-08-10_15...</td>\n",
       "      <td>233.735757</td>\n",
       "      <td>173.646836</td>\n",
       "      <td>299.256248</td>\n",
       "      <td>261.007491</td>\n",
       "      <td>240.724609</td>\n",
       "      <td>187.624541</td>\n",
       "      <td>251.207888</td>\n",
       "      <td>191.118967</td>\n",
       "      <td>258.196740</td>\n",
       "      <td>185.003721</td>\n",
       "      <td>257.323134</td>\n",
       "      <td>208.591098</td>\n",
       "      <td>287.899363</td>\n",
       "      <td>194.613393</td>\n",
       "      <td>281.784117</td>\n",
       "      <td>224.316016</td>\n",
       "      <td>252.955101</td>\n",
       "      <td>259.260278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scorer Unnamed: 1_level_0  \\\n",
       "    individuals Unnamed: 1_level_1   \n",
       "      bodyparts Unnamed: 1_level_2   \n",
       "         coords Unnamed: 1_level_3   \n",
       "0  labeled-data               24.0   \n",
       "1  labeled-data               24.0   \n",
       "2  labeled-data               24.0   \n",
       "3  labeled-data               24.0   \n",
       "4  labeled-data               24.0   \n",
       "\n",
       "                                  Unnamed: 2_level_0  annotation              \\\n",
       "                                  Unnamed: 2_level_1      mouse1               \n",
       "                                  Unnamed: 2_level_2     topleft               \n",
       "                                  Unnamed: 2_level_3           x           y   \n",
       "0  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  273.048052   12.903231   \n",
       "1  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  286.152150  140.449787   \n",
       "2  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  238.977396  154.427492   \n",
       "3  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  230.241331  166.657984   \n",
       "4  A_male_in_a_new_cage_face_view_3_2022-08-10_15...  233.735757  173.646836   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "    rightdown                    nose                 leftear               \n",
       "            x           y           x           y           x           y   \n",
       "0  544.739689  331.769622  517.657886   21.639296  504.553788   51.341919   \n",
       "1  516.784280  315.171098  515.910673  175.394049  488.828870  148.312246   \n",
       "2  394.479362  225.189623  247.713462  212.085524  267.806412  203.349459   \n",
       "3  310.613133  239.167328  287.899363  192.866180  273.048052  184.130115   \n",
       "4  299.256248  261.007491  240.724609  187.624541  251.207888  191.118967   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "     rightear                 leftHip                rightHip               \n",
       "            x           y           x           y           x           y   \n",
       "0  464.367887   59.204378  532.509198  169.278803  481.840018  168.405197   \n",
       "1  457.379034  152.680279  478.345591  234.799295  425.055592  229.557655   \n",
       "2  272.174445  198.107820  300.129855  198.107820  303.624281  187.624541   \n",
       "3  280.036904  196.360606  253.828707  196.360606  269.553625  210.338311   \n",
       "4  258.196740  185.003721  257.323134  208.591098  287.899363  194.613393   \n",
       "\n",
       "                                                                             \\\n",
       "                                                   mouse2                     \n",
       "     tailBase                 tailEnd             topleft     rightdown       \n",
       "            x           y           x           y       x   y         x   y   \n",
       "0  462.620673  251.397819  307.118707  295.951753     NaN NaN       NaN NaN   \n",
       "1  412.825100  262.754704  293.141002  285.468475     NaN NaN       NaN NaN   \n",
       "2  336.821330  189.371754  404.089034  217.327164     NaN NaN       NaN NaN   \n",
       "3  245.092642  221.695196  303.624281  234.799295     NaN NaN       NaN NaN   \n",
       "4  281.784117  224.316016  252.955101  259.260278     NaN NaN       NaN NaN   \n",
       "\n",
       "                                                                           \\\n",
       "                                                                            \n",
       "  nose     leftear     rightear     leftHip     rightHip     tailBase       \n",
       "     x   y       x   y        x   y       x   y        x   y        x   y   \n",
       "0  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "1  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "2  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "3  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "4  NaN NaN     NaN NaN      NaN NaN     NaN NaN      NaN NaN      NaN NaN   \n",
       "\n",
       "               \n",
       "               \n",
       "  tailEnd      \n",
       "        x   y  \n",
       "0     NaN NaN  \n",
       "1     NaN NaN  \n",
       "2     NaN NaN  \n",
       "3     NaN NaN  \n",
       "4     NaN NaN  "
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# reading the CSV file\n",
    "path = r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\"\n",
    "\n",
    "df = pd.read_csv(path , header = [0, 1, 2, 3])\n",
    "df = pd.DataFrame(df) \n",
    "\n",
    "size = os.path.getsize(r\"C:\\Users\\ferro\\Desktop\\Disco Duro (17-08-2022) PRE-CHICAGO\\DRIVE\\University ( 28-11-2020 )\\Master\\Chicago IIT\\Julen Subjects CHICAGO IIT\\S1\\CS 584 Machine Learning\\Assignments\\HW_3\\A20512110_CollectedData_annotation.csv\")\n",
    "\n",
    "# displaying the contents of the CSV file\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, the dataset will be processed in order to get the dataset structure needed to feed the Neural Network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "58 rows were eliminated due to issues related to NaN values\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = len(df) #getting the number of data examples that we have\n",
    "\n",
    "# if we want to sample the data in order to mix it\n",
    "df = df.sample(frac = 1.00)\n",
    "\n",
    "df = df.iloc[: , 3:]\n",
    "#print(df)\n",
    "\n",
    "#getting rid of the possible NaN values\n",
    "th = 1\n",
    "df = df.dropna(axis = 0)\n",
    "df.fillna(value = 200.000)\n",
    "rows_na = len(df)\n",
    "\n",
    "mouse1 = df.xs('mouse1', level=1, axis=1)\n",
    "mouse1 = mouse1.dropna(axis = 0)\n",
    "mouse2 = df.xs('mouse2', level=1, axis=1)\n",
    "mouse2 = mouse2.dropna(axis = 0)\n",
    "\n",
    "# we add as rows the mouse2 samples' data taken in pictures where more than one mice were found\n",
    "#df = pd.concat([mouse1, mouse2], axis=0)\n",
    "df = mouse1.append(mouse2)\n",
    "\n",
    "# we create one dataset per axis with data related to its own axis\n",
    "df_x = df.xs('x', level=2, axis=1)\n",
    "df_y = df.xs('y', level=2, axis=1)\n",
    "\n",
    "# we calculate the average location of the mice in both axis\n",
    "x_cg = (df_x.xs('topleft', level=1, axis=1) + df_x.xs('rightdown', level=1, axis=1)) / 2\n",
    "y_cg = (df_y.xs('topleft', level=1, axis=1) + df_y.xs('rightdown', level=1, axis=1)) / 2\n",
    "\n",
    "# renaming the columns of the dataframes\n",
    "x_cg.rename(columns = {'annotation':'x_location'}, inplace = True)\n",
    "y_cg.rename(columns = {'annotation':'y_location'}, inplace = True)\n",
    "\n",
    "# we get rid of the data used for calculating the average location of the mice in both axis\n",
    "df = cleaning(df)\n",
    "df_x = cleaning(df_x)\n",
    "df_y = cleaning(df_y)\n",
    "\n",
    "# we add to df the calculated average location of the mice in both axis\n",
    "df = df.assign(x_locatin = x_cg)\n",
    "df = df.assign(y_location = y_cg)\n",
    "\n",
    "#print(df_x)\n",
    "# df_x is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "#print(df_y)\n",
    "# df_y is a dataset made up of 187 rows and 7 columns corresponding to the attributes\n",
    "\n",
    "#print(df)\n",
    "# df is a dataset made up of 187 rows and 16 columns ( 7 attributes per axis + one location per axis)\n",
    "\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, the fed datasets will be divided in training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = 0.2\n",
    "\n",
    "# x_cg and y_cg will be the respective results for the testing and training of the 7 atributes fed Neural Network\n",
    "# y_2d will be the respective result for the testing and training of the 14 atributes fed Neural Network\n",
    "\n",
    "y_2d = pd.concat([x_cg, y_cg], axis = 1)\n",
    "\n",
    "in_x_train, in_x_test, out_x_train, out_x_test = train_test_split(df_x, x_cg, test_size = coef)\n",
    "in_y_train, in_y_test, out_y_train,  out_y_test = train_test_split(df_y, y_cg, test_size = coef)\n",
    "in_2d_train, in_2d_test, out_2d_train, out_2d_test = train_test_split(df['annotation'], y_2d, test_size = coef)\n",
    "\n",
    "# just checking if the split is done properly according to the established 0.2 coefficient \n",
    "\n",
    "# print(in_x_test.shape)\n",
    "# print(in_y_train.shape)\n",
    "# print(in_2d_train.shape)\n",
    "# print(in_2d_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will print some of the useful datasets in order to see their structure before being fed to the Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">annotation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nose</th>\n",
       "      <th>leftear</th>\n",
       "      <th>rightear</th>\n",
       "      <th>leftHip</th>\n",
       "      <th>rightHip</th>\n",
       "      <th>tailBase</th>\n",
       "      <th>tailEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>207.527560</td>\n",
       "      <td>236.356576</td>\n",
       "      <td>250.334281</td>\n",
       "      <td>310.613133</td>\n",
       "      <td>270.427232</td>\n",
       "      <td>382.248871</td>\n",
       "      <td>282.657724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>361.282313</td>\n",
       "      <td>348.178215</td>\n",
       "      <td>372.639199</td>\n",
       "      <td>349.051822</td>\n",
       "      <td>373.512805</td>\n",
       "      <td>363.029526</td>\n",
       "      <td>370.891985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>383.122477</td>\n",
       "      <td>413.698706</td>\n",
       "      <td>403.215428</td>\n",
       "      <td>460.873460</td>\n",
       "      <td>462.620673</td>\n",
       "      <td>483.587231</td>\n",
       "      <td>540.371657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>71.244938</td>\n",
       "      <td>95.705922</td>\n",
       "      <td>93.958708</td>\n",
       "      <td>156.858380</td>\n",
       "      <td>162.100020</td>\n",
       "      <td>174.330511</td>\n",
       "      <td>294.888215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>316.728379</td>\n",
       "      <td>311.486740</td>\n",
       "      <td>296.635429</td>\n",
       "      <td>267.806412</td>\n",
       "      <td>247.713462</td>\n",
       "      <td>234.609363</td>\n",
       "      <td>253.828707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotation                                                              \\\n",
       "           nose     leftear    rightear     leftHip    rightHip    tailBase   \n",
       "36   207.527560  236.356576  250.334281  310.613133  270.427232  382.248871   \n",
       "28   361.282313  348.178215  372.639199  349.051822  373.512805  363.029526   \n",
       "85   383.122477  413.698706  403.215428  460.873460  462.620673  483.587231   \n",
       "122   71.244938   95.705922   93.958708  156.858380  162.100020  174.330511   \n",
       "49   316.728379  311.486740  296.635429  267.806412  247.713462  234.609363   \n",
       "\n",
       "                 \n",
       "        tailEnd  \n",
       "36   282.657724  \n",
       "28   370.891985  \n",
       "85   540.371657  \n",
       "122  294.888215  \n",
       "49   253.828707  "
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>297.945838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>359.535100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>463.494280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>174.767315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>266.932806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_location\n",
       "36   297.945838\n",
       "28   359.535100\n",
       "85   463.494280\n",
       "122  174.767315\n",
       "49   266.932806"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">nose</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightear</th>\n",
       "      <th colspan=\"2\" halign=\"left\">leftHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rightHip</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailBase</th>\n",
       "      <th colspan=\"2\" halign=\"left\">tailEnd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>425.929198</td>\n",
       "      <td>236.546508</td>\n",
       "      <td>413.698706</td>\n",
       "      <td>221.695196</td>\n",
       "      <td>439.906903</td>\n",
       "      <td>224.316016</td>\n",
       "      <td>393.605756</td>\n",
       "      <td>250.524213</td>\n",
       "      <td>433.791657</td>\n",
       "      <td>261.007491</td>\n",
       "      <td>392.732149</td>\n",
       "      <td>259.260278</td>\n",
       "      <td>293.141002</td>\n",
       "      <td>287.215688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>289.646576</td>\n",
       "      <td>210.338311</td>\n",
       "      <td>270.427232</td>\n",
       "      <td>200.728639</td>\n",
       "      <td>273.921658</td>\n",
       "      <td>205.970279</td>\n",
       "      <td>240.724609</td>\n",
       "      <td>207.717492</td>\n",
       "      <td>263.438380</td>\n",
       "      <td>217.327164</td>\n",
       "      <td>244.219035</td>\n",
       "      <td>219.074377</td>\n",
       "      <td>228.494117</td>\n",
       "      <td>252.271426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>358.661494</td>\n",
       "      <td>291.583721</td>\n",
       "      <td>343.810182</td>\n",
       "      <td>253.145032</td>\n",
       "      <td>321.970019</td>\n",
       "      <td>261.007491</td>\n",
       "      <td>300.129855</td>\n",
       "      <td>261.881098</td>\n",
       "      <td>263.438380</td>\n",
       "      <td>274.985196</td>\n",
       "      <td>272.174445</td>\n",
       "      <td>257.513065</td>\n",
       "      <td>287.025756</td>\n",
       "      <td>241.788147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>538.624443</td>\n",
       "      <td>203.349459</td>\n",
       "      <td>529.014771</td>\n",
       "      <td>198.981426</td>\n",
       "      <td>508.048214</td>\n",
       "      <td>212.085524</td>\n",
       "      <td>509.795427</td>\n",
       "      <td>256.639459</td>\n",
       "      <td>485.334444</td>\n",
       "      <td>262.754704</td>\n",
       "      <td>465.241493</td>\n",
       "      <td>276.732409</td>\n",
       "      <td>358.661494</td>\n",
       "      <td>302.940606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>328.958871</td>\n",
       "      <td>178.014869</td>\n",
       "      <td>303.624281</td>\n",
       "      <td>170.152410</td>\n",
       "      <td>299.256248</td>\n",
       "      <td>178.014869</td>\n",
       "      <td>259.943953</td>\n",
       "      <td>221.695196</td>\n",
       "      <td>252.955101</td>\n",
       "      <td>231.304869</td>\n",
       "      <td>235.482970</td>\n",
       "      <td>230.431262</td>\n",
       "      <td>245.966248</td>\n",
       "      <td>221.695196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nose                 leftear                rightear              \\\n",
       "              x           y           x           y           x           y   \n",
       "108  425.929198  236.546508  413.698706  221.695196  439.906903  224.316016   \n",
       "92   289.646576  210.338311  270.427232  200.728639  273.921658  205.970279   \n",
       "41   358.661494  291.583721  343.810182  253.145032  321.970019  261.007491   \n",
       "45   538.624443  203.349459  529.014771  198.981426  508.048214  212.085524   \n",
       "87   328.958871  178.014869  303.624281  170.152410  299.256248  178.014869   \n",
       "\n",
       "        leftHip                rightHip                tailBase              \\\n",
       "              x           y           x           y           x           y   \n",
       "108  393.605756  250.524213  433.791657  261.007491  392.732149  259.260278   \n",
       "92   240.724609  207.717492  263.438380  217.327164  244.219035  219.074377   \n",
       "41   300.129855  261.881098  263.438380  274.985196  272.174445  257.513065   \n",
       "45   509.795427  256.639459  485.334444  262.754704  465.241493  276.732409   \n",
       "87   259.943953  221.695196  252.955101  231.304869  235.482970  230.431262   \n",
       "\n",
       "        tailEnd              \n",
       "              x           y  \n",
       "108  293.141002  287.215688  \n",
       "92   228.494117  252.271426  \n",
       "41   287.025756  241.788147  \n",
       "45   358.661494  302.940606  \n",
       "87   245.966248  221.695196  "
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_2d_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_location</th>\n",
       "      <th>y_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>378.317641</td>\n",
       "      <td>249.650606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>252.518298</td>\n",
       "      <td>215.143147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>307.118707</td>\n",
       "      <td>260.133885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>449.516575</td>\n",
       "      <td>243.535360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>276.979281</td>\n",
       "      <td>210.775115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_location  y_location\n",
       "108  378.317641  249.650606\n",
       "92   252.518298  215.143147\n",
       "41   307.118707  260.133885\n",
       "45   449.516575  243.535360\n",
       "87   276.979281  210.775115"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2d_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the first model will be ran and its name will be \"THE AXIS DEPENDENT MODEL\". This model is caracterized by taking the 14 attributes as input, and giving two outputs as both coordinates of the location of the mouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step, the Neural Network model will be created by using the Tensorflow library. Then, we have to keep building up the Neural Network by establishing some other parameters, and finally, the model will be ready for the training stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"THE DEPENDENT MODEL\" the next datasets will be used: in_2d_train, in_2d_test, out_2d_train, out_2d_test\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def train(df_in, df_out, neurons, output, epoch):\n",
    "    \n",
    "    input_shape = [df_in.shape[1]]\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=neurons, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(units=neurons, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=output)\n",
    "    ])\n",
    "    \n",
    "    # printing a summary in order to check if it works\n",
    "    model.summary()\n",
    "\n",
    "    # We will use the adam optimizer due to the fact that it behaves well overally \n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    batchs = int(rows / 30)\n",
    "    losses = model.fit(\n",
    "                        df_in, df_out,\n",
    "                        batch_size = batchs,\n",
    "                        epochs = epoch\n",
    "                    )\n",
    "    model.summary()\n",
    "    return [model, losses]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the train() function has been created, we need to create the function that will run the simulations with the different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(df_in, df_out, df_in_test, df_out_test,  neurons, output, epoch):\n",
    "    results = train(df_in, df_out, neurons, output, epoch)\n",
    "    model = results[0]\n",
    "\n",
    "    pred = pd.DataFrame(model.predict(df_in_test)) \n",
    "\n",
    "    error = pred.values - df_out_test.values\n",
    "    error = pd.DataFrame(error)\n",
    "    \n",
    "    errors = [round(abs(error.iloc[:, x].mean()), 2) for x in range(df_out_test.shape[1])]\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for i in range(len(errors)):\n",
    "        print(\"The Squared Error Loss error for the {}-axis was: \".format(i), errors[i])\n",
    "    losses = results[1]\n",
    "    \n",
    "    # print(loss_df)\n",
    "    return [errors, losses]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just need to invoke the function that runs the simulations with the model parameters that we want to build and the dataset that we want to feed.\n",
    "\n",
    "This way, we will run a while with one simulation with increasing number of neurons on each loop, until the error gets lower than a threshold. Hence, we will get the minimum neuron number per layer, for a valid a model which ensures an error upper-bounded by a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_638\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1914 (Dense)          (None, 32)                480       \n",
      "                                                                 \n",
      " dense_1915 (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1916 (Dense)          (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,602\n",
      "Trainable params: 1,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 63.2019\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 30.5347\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 18.0736\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.3568\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 13.3809\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8257\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.6712\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6882\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3915\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5158\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2049\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9703\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.8720\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.1035\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9206\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.8076\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.6605\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3558\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9511\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.6937\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8299\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3209\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2701\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0596\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8704\n",
      "Model: \"sequential_638\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1914 (Dense)          (None, 32)                480       \n",
      "                                                                 \n",
      " dense_1915 (Dense)          (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_1916 (Dense)          (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,602\n",
      "Trainable params: 1,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  5.09\n",
      "The Squared Error Loss error for the 1-axis was:  3.6\n",
      "Squared Error Loss:  4.34\n",
      "Model: \"sequential_639\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1917 (Dense)          (None, 34)                510       \n",
      "                                                                 \n",
      " dense_1918 (Dense)          (None, 34)                1190      \n",
      "                                                                 \n",
      " dense_1919 (Dense)          (None, 2)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,770\n",
      "Trainable params: 1,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 163.9801\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 703us/step - loss: 34.2031\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 916us/step - loss: 14.8789\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4060\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.2228\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9029\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8648\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8546\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 9.7944\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7523\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4503\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8384\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1042\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.1437\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 985us/step - loss: 8.7606\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0502\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1686\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8259\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0481\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5095\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2678\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.8155\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5304\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6427\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.9913\n",
      "Model: \"sequential_639\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1917 (Dense)          (None, 34)                510       \n",
      "                                                                 \n",
      " dense_1918 (Dense)          (None, 34)                1190      \n",
      "                                                                 \n",
      " dense_1919 (Dense)          (None, 2)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,770\n",
      "Trainable params: 1,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  10.28\n",
      "The Squared Error Loss error for the 1-axis was:  9.34\n",
      "Squared Error Loss:  9.81\n",
      "Model: \"sequential_640\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1920 (Dense)          (None, 36)                540       \n",
      "                                                                 \n",
      " dense_1921 (Dense)          (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_1922 (Dense)          (None, 2)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,946\n",
      "Trainable params: 1,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 95.3261\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 33.1559\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 24.1396\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.4798\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 19.5959\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.6222\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.3694\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.2605\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.2127\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.0476\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8715\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9169\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0178\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9120\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.7387\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.3718\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.7024\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5225\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7199\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.4715\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.2497\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7256\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6826\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5997\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5249\n",
      "Model: \"sequential_640\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1920 (Dense)          (None, 36)                540       \n",
      "                                                                 \n",
      " dense_1921 (Dense)          (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_1922 (Dense)          (None, 2)                 74        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,946\n",
      "Trainable params: 1,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  10.65\n",
      "The Squared Error Loss error for the 1-axis was:  0.72\n",
      "Squared Error Loss:  5.68\n",
      "Model: \"sequential_641\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1923 (Dense)          (None, 38)                570       \n",
      "                                                                 \n",
      " dense_1924 (Dense)          (None, 38)                1482      \n",
      "                                                                 \n",
      " dense_1925 (Dense)          (None, 2)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,130\n",
      "Trainable params: 2,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 72.0642\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 27.9545\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 17.4909\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.6239\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.0504\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7936\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.3242\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.2007\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.2514\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3667\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 782us/step - loss: 9.7660\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.0250\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9531\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5858\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9074\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2694\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.6107\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.8844\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 852us/step - loss: 9.5935\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.3261\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8607\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.8974\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5261\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9256\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6362\n",
      "Model: \"sequential_641\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1923 (Dense)          (None, 38)                570       \n",
      "                                                                 \n",
      " dense_1924 (Dense)          (None, 38)                1482      \n",
      "                                                                 \n",
      " dense_1925 (Dense)          (None, 2)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,130\n",
      "Trainable params: 2,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  9.55\n",
      "The Squared Error Loss error for the 1-axis was:  3.13\n",
      "Squared Error Loss:  6.34\n",
      "Model: \"sequential_642\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1926 (Dense)          (None, 40)                600       \n",
      "                                                                 \n",
      " dense_1927 (Dense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_1928 (Dense)          (None, 2)                 82        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 96.9540\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 45.4164\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 32.6969\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 22.7159\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.6389\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.6333\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6486\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2422\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1271\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.1120\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6498\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.2443\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8158\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9408\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6006\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 765us/step - loss: 9.0539\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6053\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.9375\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.2077\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4273\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9365\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2927\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2549\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1931\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9735\n",
      "Model: \"sequential_642\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1926 (Dense)          (None, 40)                600       \n",
      "                                                                 \n",
      " dense_1927 (Dense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_1928 (Dense)          (None, 2)                 82        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  3.09\n",
      "The Squared Error Loss error for the 1-axis was:  11.09\n",
      "Squared Error Loss:  7.09\n",
      "Model: \"sequential_643\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1929 (Dense)          (None, 42)                630       \n",
      "                                                                 \n",
      " dense_1930 (Dense)          (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_1931 (Dense)          (None, 2)                 86        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,522\n",
      "Trainable params: 2,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 262.3427\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 836us/step - loss: 46.0395\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 891us/step - loss: 21.8023\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.0054\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.9637\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5646\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9550\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3629\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7244\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5474\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6285\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0795\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6155\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2411\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6304\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9805\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1405\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.7259\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3751\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3202\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 847us/step - loss: 9.3479\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2345\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4720\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.4075\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3725\n",
      "Model: \"sequential_643\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1929 (Dense)          (None, 42)                630       \n",
      "                                                                 \n",
      " dense_1930 (Dense)          (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_1931 (Dense)          (None, 2)                 86        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,522\n",
      "Trainable params: 2,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  11.75\n",
      "The Squared Error Loss error for the 1-axis was:  4.89\n",
      "Squared Error Loss:  8.32\n",
      "Model: \"sequential_644\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1932 (Dense)          (None, 44)                660       \n",
      "                                                                 \n",
      " dense_1933 (Dense)          (None, 44)                1980      \n",
      "                                                                 \n",
      " dense_1934 (Dense)          (None, 2)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,730\n",
      "Trainable params: 2,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 94.2966\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 35.4656\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 22.6081\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 15.6268\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.5356\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.9279\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.0737\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.9618\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9788\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3415\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.2962\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4902\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4525\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.4108\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8027\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8848\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0590\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4448\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.8874\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5541\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5625\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.2967\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.4479\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.4406\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9407\n",
      "Model: \"sequential_644\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1932 (Dense)          (None, 44)                660       \n",
      "                                                                 \n",
      " dense_1933 (Dense)          (None, 44)                1980      \n",
      "                                                                 \n",
      " dense_1934 (Dense)          (None, 2)                 90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,730\n",
      "Trainable params: 2,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  2.1\n",
      "The Squared Error Loss error for the 1-axis was:  7.38\n",
      "Squared Error Loss:  4.74\n",
      "Model: \"sequential_645\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1935 (Dense)          (None, 46)                690       \n",
      "                                                                 \n",
      " dense_1936 (Dense)          (None, 46)                2162      \n",
      "                                                                 \n",
      " dense_1937 (Dense)          (None, 2)                 94        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,946\n",
      "Trainable params: 2,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 75.9497\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 19.3287\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.2117\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3410\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.0955\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.0622\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0289\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.3706\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7300\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1236\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8539\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4652\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9220\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4790\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9790\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.3095\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 890us/step - loss: 10.3283\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4047\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3827\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.2435\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9924\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8327\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.7115\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5926\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4753\n",
      "Model: \"sequential_645\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1935 (Dense)          (None, 46)                690       \n",
      "                                                                 \n",
      " dense_1936 (Dense)          (None, 46)                2162      \n",
      "                                                                 \n",
      " dense_1937 (Dense)          (None, 2)                 94        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,946\n",
      "Trainable params: 2,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  7.46\n",
      "The Squared Error Loss error for the 1-axis was:  12.3\n",
      "Squared Error Loss:  9.88\n",
      "Model: \"sequential_646\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1938 (Dense)          (None, 48)                720       \n",
      "                                                                 \n",
      " dense_1939 (Dense)          (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_1940 (Dense)          (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,170\n",
      "Trainable params: 3,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 127.9343\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 37.6916\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 23.7824\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 19.5047\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 16.3488\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.7559\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3806\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8575\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1869\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5254\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7929\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8964\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2987\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7061\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.4997\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7620\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9272\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4824\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7933\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6983\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3105\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9057\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6339\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5549\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0266\n",
      "Model: \"sequential_646\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1938 (Dense)          (None, 48)                720       \n",
      "                                                                 \n",
      " dense_1939 (Dense)          (None, 48)                2352      \n",
      "                                                                 \n",
      " dense_1940 (Dense)          (None, 2)                 98        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,170\n",
      "Trainable params: 3,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  2.11\n",
      "The Squared Error Loss error for the 1-axis was:  6.66\n",
      "Squared Error Loss:  4.38\n",
      "Model: \"sequential_647\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1941 (Dense)          (None, 50)                750       \n",
      "                                                                 \n",
      " dense_1942 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1943 (Dense)          (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 123.1154\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 37.4072\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 22.0690\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.9767\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.9379\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.9233\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7742\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0027\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0589\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9259\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5126\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5107\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6924\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.1167\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.3580\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6687\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3993\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5930\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.7901\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9486\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7620\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6747\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.0164\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8412\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.2297\n",
      "Model: \"sequential_647\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1941 (Dense)          (None, 50)                750       \n",
      "                                                                 \n",
      " dense_1942 (Dense)          (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1943 (Dense)          (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,402\n",
      "Trainable params: 3,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  15.52\n",
      "The Squared Error Loss error for the 1-axis was:  22.24\n",
      "Squared Error Loss:  18.88\n",
      "Model: \"sequential_648\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1944 (Dense)          (None, 52)                780       \n",
      "                                                                 \n",
      " dense_1945 (Dense)          (None, 52)                2756      \n",
      "                                                                 \n",
      " dense_1946 (Dense)          (None, 2)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 31.5355\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.0193\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.4579\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7854\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0940\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 937us/step - loss: 8.4972\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6972\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2534\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6496\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6166\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4631\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5870\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.6216\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4552\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4083\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2064\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.0691\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.2213\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.4401\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4212\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3209\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.4857\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5886\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9313\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6410\n",
      "Model: \"sequential_648\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1944 (Dense)          (None, 52)                780       \n",
      "                                                                 \n",
      " dense_1945 (Dense)          (None, 52)                2756      \n",
      "                                                                 \n",
      " dense_1946 (Dense)          (None, 2)                 106       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  8.94\n",
      "The Squared Error Loss error for the 1-axis was:  6.49\n",
      "Squared Error Loss:  7.72\n",
      "Model: \"sequential_649\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1947 (Dense)          (None, 54)                810       \n",
      "                                                                 \n",
      " dense_1948 (Dense)          (None, 54)                2970      \n",
      "                                                                 \n",
      " dense_1949 (Dense)          (None, 2)                 110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,890\n",
      "Trainable params: 3,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 165.4886\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 29.4788\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.6669\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.8477\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.1361\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4170\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.6090\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0712\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.9243\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6029\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1038\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9785\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6926\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5964\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8993\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4964\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7481\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.6606\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0365\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2915\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2164\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1980\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7640\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8086\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0595\n",
      "Model: \"sequential_649\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1947 (Dense)          (None, 54)                810       \n",
      "                                                                 \n",
      " dense_1948 (Dense)          (None, 54)                2970      \n",
      "                                                                 \n",
      " dense_1949 (Dense)          (None, 2)                 110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,890\n",
      "Trainable params: 3,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  13.12\n",
      "The Squared Error Loss error for the 1-axis was:  2.01\n",
      "Squared Error Loss:  7.56\n",
      "Model: \"sequential_650\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1950 (Dense)          (None, 56)                840       \n",
      "                                                                 \n",
      " dense_1951 (Dense)          (None, 56)                3192      \n",
      "                                                                 \n",
      " dense_1952 (Dense)          (None, 2)                 114       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,146\n",
      "Trainable params: 4,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 182.3919\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 32.9018\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 21.1490\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 16.2387\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.5622\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.3677\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.1855\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5472\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5241\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1207\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8083\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.3852\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.3783\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3665\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1898\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8535\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1924\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1736\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.9164\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.1592\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6719\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5999\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7429\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9228\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8922\n",
      "Model: \"sequential_650\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1950 (Dense)          (None, 56)                840       \n",
      "                                                                 \n",
      " dense_1951 (Dense)          (None, 56)                3192      \n",
      "                                                                 \n",
      " dense_1952 (Dense)          (None, 2)                 114       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,146\n",
      "Trainable params: 4,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  8.64\n",
      "The Squared Error Loss error for the 1-axis was:  2.96\n",
      "Squared Error Loss:  5.8\n",
      "Model: \"sequential_651\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1953 (Dense)          (None, 58)                870       \n",
      "                                                                 \n",
      " dense_1954 (Dense)          (None, 58)                3422      \n",
      "                                                                 \n",
      " dense_1955 (Dense)          (None, 2)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,410\n",
      "Trainable params: 4,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 186.6591\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 27.9254\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.9728\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9408\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7330\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.9607\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4260\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9858\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5614\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8807\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9689\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3215\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.2794\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6651\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9599\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.2339\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 8.4527\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.7516\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7608\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.0568\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2536\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.6959\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.0204\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3911\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5493\n",
      "Model: \"sequential_651\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1953 (Dense)          (None, 58)                870       \n",
      "                                                                 \n",
      " dense_1954 (Dense)          (None, 58)                3422      \n",
      "                                                                 \n",
      " dense_1955 (Dense)          (None, 2)                 118       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,410\n",
      "Trainable params: 4,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  5.41\n",
      "The Squared Error Loss error for the 1-axis was:  12.61\n",
      "Squared Error Loss:  9.01\n",
      "Model: \"sequential_652\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1956 (Dense)          (None, 60)                900       \n",
      "                                                                 \n",
      " dense_1957 (Dense)          (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_1958 (Dense)          (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,682\n",
      "Trainable params: 4,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 96.5903\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 21.8459\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.7420\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.2539\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3865\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3421\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.4750\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 10.1585\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.8438\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.0148\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0885\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2326\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.3911\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.0536\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8392\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3347\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7735\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5026\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7400\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 8.0843\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8062\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0218\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.0273\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7814\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7366\n",
      "Model: \"sequential_652\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1956 (Dense)          (None, 60)                900       \n",
      "                                                                 \n",
      " dense_1957 (Dense)          (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_1958 (Dense)          (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,682\n",
      "Trainable params: 4,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  23.42\n",
      "The Squared Error Loss error for the 1-axis was:  3.83\n",
      "Squared Error Loss:  13.62\n",
      "Model: \"sequential_653\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1959 (Dense)          (None, 62)                930       \n",
      "                                                                 \n",
      " dense_1960 (Dense)          (None, 62)                3906      \n",
      "                                                                 \n",
      " dense_1961 (Dense)          (None, 2)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,962\n",
      "Trainable params: 4,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 129.1145\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 39.1538\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 26.3071\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 16.9392\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.3757\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0085\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9711\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6446\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0040\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6817\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.4294\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1265\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5620\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9548\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6921\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7760\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1299\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.3576\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.2267\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4332\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1408\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4257\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6226\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2321\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3988\n",
      "Model: \"sequential_653\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1959 (Dense)          (None, 62)                930       \n",
      "                                                                 \n",
      " dense_1960 (Dense)          (None, 62)                3906      \n",
      "                                                                 \n",
      " dense_1961 (Dense)          (None, 2)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,962\n",
      "Trainable params: 4,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  6.97\n",
      "The Squared Error Loss error for the 1-axis was:  5.18\n",
      "Squared Error Loss:  6.07\n",
      "Model: \"sequential_654\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1962 (Dense)          (None, 64)                960       \n",
      "                                                                 \n",
      " dense_1963 (Dense)          (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1964 (Dense)          (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 131.6467\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 24.0139\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.9785\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2141\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9877\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9680\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4688\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8824\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0508\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0883\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7099\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8648\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1628\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3761\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1435\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3086\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3392\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9789\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6885\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9115\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.8449\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2456\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.8159\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1242\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4519\n",
      "Model: \"sequential_654\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1962 (Dense)          (None, 64)                960       \n",
      "                                                                 \n",
      " dense_1963 (Dense)          (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1964 (Dense)          (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  6.4\n",
      "The Squared Error Loss error for the 1-axis was:  7.16\n",
      "Squared Error Loss:  6.78\n",
      "Model: \"sequential_655\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1965 (Dense)          (None, 66)                990       \n",
      "                                                                 \n",
      " dense_1966 (Dense)          (None, 66)                4422      \n",
      "                                                                 \n",
      " dense_1967 (Dense)          (None, 2)                 134       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,546\n",
      "Trainable params: 5,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 153.5763\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 38.2282\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.2716\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2030\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.7236\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.1753\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1554\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6390\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1236\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.3974\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.1803\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9636\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8562\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.0978\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7852\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5971\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6967\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5285\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.5115\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1588\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.4923\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1399\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9651\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9243\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.8513\n",
      "Model: \"sequential_655\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1965 (Dense)          (None, 66)                990       \n",
      "                                                                 \n",
      " dense_1966 (Dense)          (None, 66)                4422      \n",
      "                                                                 \n",
      " dense_1967 (Dense)          (None, 2)                 134       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,546\n",
      "Trainable params: 5,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  7.83\n",
      "The Squared Error Loss error for the 1-axis was:  5.71\n",
      "Squared Error Loss:  6.77\n",
      "Model: \"sequential_656\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1968 (Dense)          (None, 68)                1020      \n",
      "                                                                 \n",
      " dense_1969 (Dense)          (None, 68)                4692      \n",
      "                                                                 \n",
      " dense_1970 (Dense)          (None, 2)                 138       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,850\n",
      "Trainable params: 5,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 82.3820\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 25.9317\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 15.8146\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.5713\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.3095\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.3798\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6547\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8451\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6449\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.9270\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8259\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0054\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 984us/step - loss: 9.7056\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3532\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3299\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2795\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3645\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6453\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5984\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8168\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5057\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0998\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.2372\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7167\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6965\n",
      "Model: \"sequential_656\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1968 (Dense)          (None, 68)                1020      \n",
      "                                                                 \n",
      " dense_1969 (Dense)          (None, 68)                4692      \n",
      "                                                                 \n",
      " dense_1970 (Dense)          (None, 2)                 138       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,850\n",
      "Trainable params: 5,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  10.91\n",
      "The Squared Error Loss error for the 1-axis was:  3.12\n",
      "Squared Error Loss:  7.02\n",
      "Model: \"sequential_657\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1971 (Dense)          (None, 70)                1050      \n",
      "                                                                 \n",
      " dense_1972 (Dense)          (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_1973 (Dense)          (None, 2)                 142       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,162\n",
      "Trainable params: 6,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 115.7240\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 21.2508\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.8684\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.4152\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2981\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6413\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7294\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.1037\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3431\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3371\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1367\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3562\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7739\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3892\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.3762\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 10.4044\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.3635\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3995\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0239\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0239\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7791\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8499\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6223\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5454\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6536\n",
      "Model: \"sequential_657\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1971 (Dense)          (None, 70)                1050      \n",
      "                                                                 \n",
      " dense_1972 (Dense)          (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_1973 (Dense)          (None, 2)                 142       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,162\n",
      "Trainable params: 6,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  9.75\n",
      "The Squared Error Loss error for the 1-axis was:  7.97\n",
      "Squared Error Loss:  8.86\n",
      "Model: \"sequential_658\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1974 (Dense)          (None, 72)                1080      \n",
      "                                                                 \n",
      " dense_1975 (Dense)          (None, 72)                5256      \n",
      "                                                                 \n",
      " dense_1976 (Dense)          (None, 2)                 146       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,482\n",
      "Trainable params: 6,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 48.2249\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.4922\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 12.3389\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0383\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7607\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3659\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5704\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1393\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9234\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5900\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7344\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.0680\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8787\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4781\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 12.5441\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0148\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7472\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8742\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.5824\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5647\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6535\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3867\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5217\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6443\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8884\n",
      "Model: \"sequential_658\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1974 (Dense)          (None, 72)                1080      \n",
      "                                                                 \n",
      " dense_1975 (Dense)          (None, 72)                5256      \n",
      "                                                                 \n",
      " dense_1976 (Dense)          (None, 2)                 146       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,482\n",
      "Trainable params: 6,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  14.96\n",
      "The Squared Error Loss error for the 1-axis was:  5.34\n",
      "Squared Error Loss:  10.15\n",
      "Model: \"sequential_659\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1977 (Dense)          (None, 74)                1110      \n",
      "                                                                 \n",
      " dense_1978 (Dense)          (None, 74)                5550      \n",
      "                                                                 \n",
      " dense_1979 (Dense)          (None, 2)                 150       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,810\n",
      "Trainable params: 6,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 74.5784\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 15.2871\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.6666\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2898\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3616\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1239\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7124\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9382\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2754\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.9866\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4319\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3467\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 889us/step - loss: 9.1876\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.4961\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.1285\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8863\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7145\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4204\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 866us/step - loss: 8.0015\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5963\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9513\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1478\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9019\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8203\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8357\n",
      "Model: \"sequential_659\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1977 (Dense)          (None, 74)                1110      \n",
      "                                                                 \n",
      " dense_1978 (Dense)          (None, 74)                5550      \n",
      "                                                                 \n",
      " dense_1979 (Dense)          (None, 2)                 150       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,810\n",
      "Trainable params: 6,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  2.45\n",
      "The Squared Error Loss error for the 1-axis was:  6.84\n",
      "Squared Error Loss:  4.64\n",
      "Model: \"sequential_660\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1980 (Dense)          (None, 76)                1140      \n",
      "                                                                 \n",
      " dense_1981 (Dense)          (None, 76)                5852      \n",
      "                                                                 \n",
      " dense_1982 (Dense)          (None, 2)                 154       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,146\n",
      "Trainable params: 7,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 76.1094\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 15.3903\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.0464\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.6874\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6259\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6886\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.8653\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5267\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8534\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6807\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5712\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2662\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2697\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5900\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7104\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5711\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3987\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0776\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.8028\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.8827\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 939us/step - loss: 8.6106\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1673\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.3560\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5043\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7112\n",
      "Model: \"sequential_660\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1980 (Dense)          (None, 76)                1140      \n",
      "                                                                 \n",
      " dense_1981 (Dense)          (None, 76)                5852      \n",
      "                                                                 \n",
      " dense_1982 (Dense)          (None, 2)                 154       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,146\n",
      "Trainable params: 7,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  8.08\n",
      "The Squared Error Loss error for the 1-axis was:  13.56\n",
      "Squared Error Loss:  10.82\n",
      "Model: \"sequential_661\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1983 (Dense)          (None, 78)                1170      \n",
      "                                                                 \n",
      " dense_1984 (Dense)          (None, 78)                6162      \n",
      "                                                                 \n",
      " dense_1985 (Dense)          (None, 2)                 158       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,490\n",
      "Trainable params: 7,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 77.5761\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 17.3597\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.3135\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.9678\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1314\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.4426\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.3795\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4512\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2361\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9985\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0437\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5073\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.5316\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.7154\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.9577\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.0483\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2346\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.0506\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7885\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2099\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9169\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5219\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1526\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9421\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5651\n",
      "Model: \"sequential_661\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1983 (Dense)          (None, 78)                1170      \n",
      "                                                                 \n",
      " dense_1984 (Dense)          (None, 78)                6162      \n",
      "                                                                 \n",
      " dense_1985 (Dense)          (None, 2)                 158       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,490\n",
      "Trainable params: 7,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  0.09\n",
      "The Squared Error Loss error for the 1-axis was:  12.22\n",
      "Squared Error Loss:  6.16\n",
      "Model: \"sequential_662\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1986 (Dense)          (None, 80)                1200      \n",
      "                                                                 \n",
      " dense_1987 (Dense)          (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_1988 (Dense)          (None, 2)                 162       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 82.9509\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 22.8280\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 15.8624\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.8414\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7712\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5372\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7710\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.0015\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4660\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.6575\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8905\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5600\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8968\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9873\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9288\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6578\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5111\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6542\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9643\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.7288\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8813\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9043\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.3930\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7397\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4667\n",
      "Model: \"sequential_662\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1986 (Dense)          (None, 80)                1200      \n",
      "                                                                 \n",
      " dense_1987 (Dense)          (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_1988 (Dense)          (None, 2)                 162       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  16.39\n",
      "The Squared Error Loss error for the 1-axis was:  7.4\n",
      "Squared Error Loss:  11.9\n",
      "Model: \"sequential_663\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1989 (Dense)          (None, 82)                1230      \n",
      "                                                                 \n",
      " dense_1990 (Dense)          (None, 82)                6806      \n",
      "                                                                 \n",
      " dense_1991 (Dense)          (None, 2)                 166       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,202\n",
      "Trainable params: 8,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 71.1294\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.1170\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.4442\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.1097\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.1281\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.9626\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7692\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.8388\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.0084\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.7388\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9505\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6849\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7666\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2880\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9879\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.9942\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6215\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1472\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7840\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 9.5115\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.8690\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.1636\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.9823\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.8078\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 8.0356\n",
      "Model: \"sequential_663\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1989 (Dense)          (None, 82)                1230      \n",
      "                                                                 \n",
      " dense_1990 (Dense)          (None, 82)                6806      \n",
      "                                                                 \n",
      " dense_1991 (Dense)          (None, 2)                 166       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,202\n",
      "Trainable params: 8,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  9.88\n",
      "The Squared Error Loss error for the 1-axis was:  2.74\n",
      "Squared Error Loss:  6.31\n",
      "Model: \"sequential_664\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1992 (Dense)          (None, 84)                1260      \n",
      "                                                                 \n",
      " dense_1993 (Dense)          (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_1994 (Dense)          (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,570\n",
      "Trainable params: 8,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 111.1624\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 28.4707\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.4643\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.3423\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3066\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.5445\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.1065\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.9501\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.5535\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.3061\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.8757\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.8632\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 10.9589\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2653\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8205\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9365\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3979\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3338\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9476\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5010\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8093\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2134\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2600\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3527\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5881\n",
      "Model: \"sequential_664\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1992 (Dense)          (None, 84)                1260      \n",
      "                                                                 \n",
      " dense_1993 (Dense)          (None, 84)                7140      \n",
      "                                                                 \n",
      " dense_1994 (Dense)          (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,570\n",
      "Trainable params: 8,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  4.95\n",
      "The Squared Error Loss error for the 1-axis was:  0.8\n",
      "Squared Error Loss:  2.88\n",
      "Model: \"sequential_665\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1995 (Dense)          (None, 86)                1290      \n",
      "                                                                 \n",
      " dense_1996 (Dense)          (None, 86)                7482      \n",
      "                                                                 \n",
      " dense_1997 (Dense)          (None, 2)                 174       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,946\n",
      "Trainable params: 8,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 73.5957\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 17.1222\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.9291\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.2192\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.6977\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6759\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9585\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0533\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.1227\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6087\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9461\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7777\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6030\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7540\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6219\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.6962\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0584\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4073\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.2889\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.0145\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1166\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7723\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5804\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9625\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5516\n",
      "Model: \"sequential_665\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1995 (Dense)          (None, 86)                1290      \n",
      "                                                                 \n",
      " dense_1996 (Dense)          (None, 86)                7482      \n",
      "                                                                 \n",
      " dense_1997 (Dense)          (None, 2)                 174       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,946\n",
      "Trainable params: 8,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  4.02\n",
      "The Squared Error Loss error for the 1-axis was:  4.28\n",
      "Squared Error Loss:  4.15\n",
      "Model: \"sequential_666\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1998 (Dense)          (None, 88)                1320      \n",
      "                                                                 \n",
      " dense_1999 (Dense)          (None, 88)                7832      \n",
      "                                                                 \n",
      " dense_2000 (Dense)          (None, 2)                 178       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,330\n",
      "Trainable params: 9,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 100.0695\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 19.8844\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.2478\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.7981\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.4472\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7771\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 877us/step - loss: 10.8709\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.4605\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0953\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.9996\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3172\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8212\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5807\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.0726\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3198\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8517\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8546\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.7027\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5445\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.9797\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3485\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.8761\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0341\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6644\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.9183\n",
      "Model: \"sequential_666\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1998 (Dense)          (None, 88)                1320      \n",
      "                                                                 \n",
      " dense_1999 (Dense)          (None, 88)                7832      \n",
      "                                                                 \n",
      " dense_2000 (Dense)          (None, 2)                 178       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,330\n",
      "Trainable params: 9,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  2.15\n",
      "The Squared Error Loss error for the 1-axis was:  3.02\n",
      "Squared Error Loss:  2.58\n",
      "Model: \"sequential_667\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2001 (Dense)          (None, 90)                1350      \n",
      "                                                                 \n",
      " dense_2002 (Dense)          (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_2003 (Dense)          (None, 2)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,722\n",
      "Trainable params: 9,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 52.6095\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 15.7919\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.2917\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5522\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5419\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.9010\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7359\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.9079\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.0639\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7513\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7993\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0947\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5333\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7806\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.8478\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1966\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5217\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0088\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.6141\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.2668\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.0991\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.9269\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0265\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.5201\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4342\n",
      "Model: \"sequential_667\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2001 (Dense)          (None, 90)                1350      \n",
      "                                                                 \n",
      " dense_2002 (Dense)          (None, 90)                8190      \n",
      "                                                                 \n",
      " dense_2003 (Dense)          (None, 2)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,722\n",
      "Trainable params: 9,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  3.5\n",
      "The Squared Error Loss error for the 1-axis was:  16.95\n",
      "Squared Error Loss:  10.22\n",
      "Model: \"sequential_668\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2004 (Dense)          (None, 92)                1380      \n",
      "                                                                 \n",
      " dense_2005 (Dense)          (None, 92)                8556      \n",
      "                                                                 \n",
      " dense_2006 (Dense)          (None, 2)                 186       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,122\n",
      "Trainable params: 10,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 79.2826\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.6933\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.0453\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.6578\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.0116\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 14.3680\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0598\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.5848\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 11.1976\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.2407\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2478\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5500\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 12.3278\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6685\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5360\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9845\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1291\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.0242\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2153\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.1154\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6944\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8299\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6325\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.7543\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.8384\n",
      "Model: \"sequential_668\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2004 (Dense)          (None, 92)                1380      \n",
      "                                                                 \n",
      " dense_2005 (Dense)          (None, 92)                8556      \n",
      "                                                                 \n",
      " dense_2006 (Dense)          (None, 2)                 186       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,122\n",
      "Trainable params: 10,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  7.87\n",
      "The Squared Error Loss error for the 1-axis was:  0.06\n",
      "Squared Error Loss:  3.96\n",
      "Model: \"sequential_669\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2007 (Dense)          (None, 94)                1410      \n",
      "                                                                 \n",
      " dense_2008 (Dense)          (None, 94)                8930      \n",
      "                                                                 \n",
      " dense_2009 (Dense)          (None, 2)                 190       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,530\n",
      "Trainable params: 10,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 2ms/step - loss: 71.4234\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 18.4907\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.6621\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.6205\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 11.2002\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.4043\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.1389\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.0502\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.7820\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1366\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7362\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.1881\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9766\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.3643\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.9350\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.4445\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4512\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1629\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.0462\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5511\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.4742\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.5701\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.5438\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.0794\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2368\n",
      "Model: \"sequential_669\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2007 (Dense)          (None, 94)                1410      \n",
      "                                                                 \n",
      " dense_2008 (Dense)          (None, 94)                8930      \n",
      "                                                                 \n",
      " dense_2009 (Dense)          (None, 2)                 190       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,530\n",
      "Trainable params: 10,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  9.13\n",
      "The Squared Error Loss error for the 1-axis was:  6.74\n",
      "Squared Error Loss:  7.94\n",
      "Model: \"sequential_670\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2010 (Dense)          (None, 96)                1440      \n",
      "                                                                 \n",
      " dense_2011 (Dense)          (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_2012 (Dense)          (None, 2)                 194       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,946\n",
      "Trainable params: 10,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 75.5864\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.9678\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.2781\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.6308\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.0930\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.6219\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.9341\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2215\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.3956\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.3514\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.1779\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0532\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1545\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.6288\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.2710\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.5026\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.9700\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.4912\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.5267\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.0411\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 10.1924\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.2708\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.4869\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.5447\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.9197\n",
      "Model: \"sequential_670\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2010 (Dense)          (None, 96)                1440      \n",
      "                                                                 \n",
      " dense_2011 (Dense)          (None, 96)                9312      \n",
      "                                                                 \n",
      " dense_2012 (Dense)          (None, 2)                 194       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,946\n",
      "Trainable params: 10,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  11.85\n",
      "The Squared Error Loss error for the 1-axis was:  2.3\n",
      "Squared Error Loss:  7.07\n",
      "Model: \"sequential_671\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2013 (Dense)          (None, 98)                1470      \n",
      "                                                                 \n",
      " dense_2014 (Dense)          (None, 98)                9702      \n",
      "                                                                 \n",
      " dense_2015 (Dense)          (None, 2)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,370\n",
      "Trainable params: 11,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "27/27 [==============================] - 1s 1ms/step - loss: 86.1642\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 22.8783\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 14.2677\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 13.3993\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.5986\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.8207\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4809\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.4360\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 10.2709\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 12.8140\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.7891\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.6593\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.0038\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.0626\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 11.5827\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 13.2590\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.5367\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 9.7373\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 9.6545\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.8868\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 9.6823\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 8.3914\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 8.4235\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.0691\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 8.3283\n",
      "Model: \"sequential_671\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2013 (Dense)          (None, 98)                1470      \n",
      "                                                                 \n",
      " dense_2014 (Dense)          (None, 98)                9702      \n",
      "                                                                 \n",
      " dense_2015 (Dense)          (None, 2)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,370\n",
      "Trainable params: 11,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Squared Error Loss error for the 0-axis was:  0.29\n",
      "The Squared Error Loss error for the 1-axis was:  2.51\n",
      "Squared Error Loss:  1.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final model has 100 neurons per hidden layer\n"
     ]
    }
   ],
   "source": [
    "output = 2\n",
    "initial = 32 #set the starting number of neurons\n",
    "neurons = initial \n",
    "epoch = 25\n",
    "\n",
    "threshold = 2.0\n",
    "err = threshold + 2.0 #establishing the threshold for the Squared Error Loss ERROR based stopping criteria\n",
    "errores = [err, err]\n",
    "avg_error = np.mean(np.array(errores))\n",
    "\n",
    "\n",
    "while(avg_error > threshold):\n",
    "    results = run(in_2d_train, out_2d_train, in_2d_test, out_2d_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    avg_error = round(np.mean(np.array(errores)), 2)\n",
    "    print(\"Squared Error Loss: \", avg_error)\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    "\n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the second model will be ran and its name will be \"THE AXIS INDEPENDENT MODEL\". This model is caracterized by taking the 7 attributes as input, and giving one output as one of the coordinates of the location of the mouse. Therefore, this model will be run two times per simulation, one for x-axis and another one for the y-axis. The point of using as input the x-axis data and the y-axis separately, that is to say, in separate models, is to check the influence of x-axis values on y-axis result and viceversa.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for the coordinates in x-axis we run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Error Loss:  1.4\n",
      "\n",
      "\n",
      "The final model has 16 neurons per hidden layer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neurons = int(initial / 2)\n",
    "output = 1\n",
    "\n",
    "\n",
    "while(errores[0] > threshold):\n",
    "    results = run(in_x_train, out_x_train, in_x_test, out_x_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    " \n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "    \n",
    "avg_error = round(np.mean(np.array(errores)), 2)\n",
    "print(\"Squared Error Loss: \", avg_error)\n",
    "print(\"\\n\")\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run it for the coordinates in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Error Loss:  1.4\n",
      "\n",
      "\n",
      "The final model has 16 neurons per hidden layer\n"
     ]
    }
   ],
   "source": [
    "output = 1\n",
    "neurons = int(initial / 2)\n",
    "\n",
    "\n",
    "while(errores[0] > threshold):\n",
    "    results = run(in_y_train, out_y_train, in_y_test, out_y_test, neurons, output, epoch)\n",
    "    errores = results[0]\n",
    "    neurons += 2\n",
    "    losses = results[1]\n",
    "    \n",
    "\n",
    "show_history(losses)\n",
    "plot_history(losses)\n",
    "plt.close()\n",
    "avg_error = round(np.mean(np.array(errores)), 2)\n",
    "print(\"Squared Error Loss: \", avg_error)\n",
    "print(\"\\n\")\n",
    "print(\"The final model has {} neurons per hidden layer\".format(neurons))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fec7c492cb63a891b61f6a129c254b2f9b08ab3c88ef1c1ffe13c4cf2a66800d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
